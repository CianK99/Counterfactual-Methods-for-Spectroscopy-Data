{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5211db",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5111aaf",
   "metadata": {},
   "source": [
    "Cleaner Version only including correct CFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "THR = 0.04  # threshold for highlighting CF changes. Needed sincse autoencoded methods can have negligible changes across many indices\n",
    "\n",
    "def _collect_glacier(root_path, kind, meth):\n",
    "    out = []\n",
    "    for npz_file in (root_path / kind).glob(f\"cf_fold*_{meth}.npz\"):\n",
    "        with np.load(npz_file) as Z:\n",
    "            for i, (o, c, t, a, b) in enumerate(zip(Z[\"x_orig\"], Z[\"x_cf\"], Z[\"y_true\"], Z[\"y_pred\"], Z[\"y_cf\"])):\n",
    "                out.append({\"x0\": o, \"xcf\": c, \"y_true\": int(t), \"y0\": int(a), \"ycf\": int(b)})\n",
    "    return out\n",
    "\n",
    "def _collect_cels(root_path, mode):\n",
    "    out = []\n",
    "    for npz_file in (root_path / mode).glob(\"cf_fold*.npz\"):\n",
    "        with np.load(npz_file, allow_pickle=True) as Z:\n",
    "            for i in range(len(Z[\"x0\"])):\n",
    "                out.append({\"x0\": Z[\"x0\"][i], \"xcf\": Z[\"xcf\"][i],\n",
    "                            \"y_true\": int(Z[\"y_true\"][i]),\n",
    "                            \"y0\": int(Z[\"y_pred\"][i]),\n",
    "                            \"ycf\": int(Z[\"y_cf\"][i])})\n",
    "    return out\n",
    "\n",
    "def _collect_rsf(root_path, mode):\n",
    "    out = []\n",
    "    for npz_file in (root_path / mode / \"rsf\").glob(\"cf_fold*.npz\"):\n",
    "        with np.load(npz_file) as Z:\n",
    "            for i in range(len(Z[\"x0\"])):\n",
    "                out.append({\"x0\": Z[\"x0\"][i], \"xcf\": Z[\"xcf\"][i],\n",
    "                            \"y_true\": int(Z[\"y_true\"][i]),\n",
    "                            \"y0\": int(Z[\"y_pred\"][i]),\n",
    "                            \"ycf\": int(Z[\"y_cf\"][i])})\n",
    "    return out\n",
    "\n",
    "def plot_cf_example(ax, item, title):\n",
    "    x0, xcf = np.squeeze(item[\"x0\"]), np.squeeze(item[\"xcf\"])\n",
    "    delta = np.abs(xcf - x0)\n",
    "    changed = delta > THR\n",
    "\n",
    "    ax.plot(x0, lw=0.7, color=\"tab:red\", label=\"Original\")\n",
    "    ax.plot(xcf, lw=1.1, color=\"grey\", ls=\":\", label=\"CF\")\n",
    "    ax.fill_between(np.arange(len(x0)), 0, 1, where=changed, color=\"gold\", alpha=0.3)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "def view(dataset_name, glacier_methods=[\"cnn\", \"ne\"], meaningful_only=False):\n",
    "    GLACIER_ROOT = Path(\"Glacier/learning-time-series-counterfactuals/cf_runs\") / dataset_name\n",
    "    CELS_ROOT = Path(\"CELS/CELS/cf_runs\") / dataset_name\n",
    "    RSF_ROOT = Path(\"RSF/RSF/cf_runs\") / dataset_name\n",
    "\n",
    "    # load data\n",
    "    glacier_data = {f\"{m}_local\": _collect_glacier(GLACIER_ROOT, \"local\", m) for m in glacier_methods}\n",
    "    glacier_data.update({f\"{m}_global\": _collect_glacier(GLACIER_ROOT, \"global\", m) for m in glacier_methods})\n",
    "    cels_local, cels_global = _collect_cels(CELS_ROOT, \"local\"), _collect_cels(CELS_ROOT, \"global\")\n",
    "    rsf_local, rsf_global = _collect_rsf(RSF_ROOT, \"local\"), _collect_rsf(RSF_ROOT, \"global\")\n",
    "\n",
    "    # work out how many rows\n",
    "    num_rows = len(glacier_methods) + 2\n",
    "    n = max(len(d) for d in list(glacier_data.values()) + [cels_local, cels_global, rsf_local, rsf_global] if d)\n",
    "\n",
    "    def _show(idx=0):\n",
    "        fig, axes = plt.subplots(num_rows, 2, figsize=(16, 4 * num_rows), sharex=True)\n",
    "\n",
    "        rows = []\n",
    "        for m in glacier_methods:\n",
    "            rows.append((f\"Glacier {m.upper()} Global\", glacier_data[f\"{m}_global\"],\n",
    "                         f\"Glacier {m.upper()} Local\",  glacier_data[f\"{m}_local\"]))\n",
    "        rows += [(\"CELS Global\", cels_global, \"CELS Local\", cels_local),\n",
    "                 (\"RSF Global\", rsf_global, \"RSF Local\", rsf_local)]\n",
    "\n",
    "        for row, (gt, gdata, lt, ldata) in enumerate(rows):\n",
    "            axg, axl = axes[row, 0], axes[row, 1]\n",
    "            if gdata:\n",
    "                plot_cf_example(axg, gdata[idx % len(gdata)], gt)\n",
    "            else:\n",
    "                axg.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\")\n",
    "            if ldata:\n",
    "                plot_cf_example(axl, ldata[idx % len(ldata)], lt)\n",
    "            else:\n",
    "                axl.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\")\n",
    "\n",
    "        axes[-1, 0].set_xlabel(\"Spectral Index\")\n",
    "        axes[-1, 1].set_xlabel(\"Spectral Index\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    interact(_show, idx=IntSlider(0, 0, n - 1, 1, description=\"Sample Index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glacier CNN (Local)...\n",
      "Loading Glacier CNN (Global)...\n",
      "Loading Glacier NE (Local)...\n",
      "Loading Glacier NE (Global)...\n",
      "Loading CELS (Local)...\n",
      "Loading CELS (Global)...\n",
      "Loading RSF (Local)...\n",
      "Loading RSF (Global)...\n",
      "\n",
      "Filtered to 8 indices where ALL methods have meaningful CFs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6828e7dfee946b5a806c413ed1e1f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample Index', max=7), Output()…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glacier CNN (Local)...\n",
      "Loading Glacier CNN (Global)...\n",
      "Loading Glacier NE (Local)...\n",
      "Loading Glacier NE (Global)...\n",
      "Loading CELS (Local)...\n",
      "Loading CELS (Global)...\n",
      "Loading RSF (Local)...\n",
      "Loading RSF (Global)...\n",
      "\n",
      "Filtered to 58 indices where ALL methods have meaningful CFs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6028861e934ba5b8ef376d6f29dd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample Index', max=57), Output(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glacier CNN (Local)...\n",
      "Loading Glacier CNN (Global)...\n",
      "Loading Glacier NE (Local)...\n",
      "Loading Glacier NE (Global)...\n",
      "Loading CELS (Local)...\n",
      "Loading CELS (Global)...\n",
      "Loading RSF (Local)...\n",
      "Loading RSF (Global)...\n",
      "\n",
      "Filtered to 129 indices where ALL methods have meaningful CFs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c6417ec4be418c84b9ef8988228c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample Index', max=128), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(dataset_name=\"EcoliVsKpneumoniae_ramanspy_singular\", meaningful_only=True)\n",
    "view(dataset_name=\"RamanCOVID19_ramanspy_preprocessed\", meaningful_only=True)\n",
    "view(dataset_name=\"DRS_TissueClassification\", meaningful_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a0c9b",
   "metadata": {},
   "source": [
    "This version Gives all CFs and provides statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "THR = 0.04\n",
    "\n",
    "def _collect_glacier(root_path, kind, meth):\n",
    "    out = []\n",
    "    data_path = root_path / kind\n",
    "    for npz_file in data_path.glob(f\"cf_fold*_{meth}.npz\"):\n",
    "        with np.load(npz_file) as Z:\n",
    "            for i, (o, c, t, a, b) in enumerate(zip(Z[\"x_orig\"], Z[\"x_cf\"], Z[\"y_true\"], Z[\"y_pred\"], Z[\"y_cf\"])):\n",
    "                out.append({\n",
    "                    \"x0\": o, \"xcf\": c,\n",
    "                    \"y_true\": int(t), \"y0\": int(a), \"ycf\": int(b),\n",
    "                    \"tag\": f\"{npz_file.name}:{i}\"\n",
    "                })\n",
    "    if not out:\n",
    "        print(f\"Warning: No Glacier CFs found for {data_path}\")\n",
    "    return out\n",
    "\n",
    "def _collect_cels(root_path, mode):\n",
    "    out = []\n",
    "    data_path = root_path / mode\n",
    "    for npz_file in data_path.glob(\"cf_fold*.npz\"):\n",
    "        with np.load(npz_file, allow_pickle=True) as Z:\n",
    "            for i in range(len(Z[\"x0\"])):\n",
    "                out.append({\n",
    "                    \"x0\": Z[\"x0\"][i], \"xcf\": Z[\"xcf\"][i],\n",
    "                    \"y_true\": int(Z[\"y_true\"][i]),\n",
    "                    \"y0\": int(Z[\"y_pred\"][i]),\n",
    "                    \"ycf\": int(Z[\"y_cf\"][i]),\n",
    "                    \"tag\": f\"{npz_file.name}:{i} ({Z['tag'][i]})\"\n",
    "                })\n",
    "    if not out:\n",
    "        print(f\"Warning: No CELS CFs found for {data_path}\")\n",
    "    return out\n",
    "\n",
    "def _collect_rsf(root_path, mode):\n",
    "    out = []\n",
    "    data_path = root_path / mode / \"rsf\"\n",
    "    for npz_file in data_path.glob(\"cf_fold*.npz\"):\n",
    "        with np.load(npz_file) as Z:\n",
    "            for i in range(len(Z[\"x0\"])):\n",
    "                out.append({\n",
    "                    \"x0\": Z[\"x0\"][i], \"xcf\": Z[\"xcf\"][i],\n",
    "                    \"y_true\": int(Z[\"y_true\"][i]),\n",
    "                    \"y0\": int(Z[\"y_pred\"][i]),\n",
    "                    \"ycf\": int(Z[\"y_cf\"][i]),\n",
    "                    \"tag\": f\"{npz_file.name}:{i}\"\n",
    "                })\n",
    "    if not out:\n",
    "        print(f\"Warning: No RSF CFs found for {data_path}\")\n",
    "    return out\n",
    "\n",
    "def view(dataset_name, glacier_meth=\"cnn\"):\n",
    "    GLACIER_ROOT = Path(\"Glacier/learning-time-series-counterfactuals/cf_runs\") / dataset_name\n",
    "    CELS_ROOT = Path(\"CELS/CELS/cf_runs\") / dataset_name\n",
    "    RSF_ROOT = Path(\"RSF/RSF/cf_runs\") / dataset_name\n",
    "\n",
    "    print(\"Loading Glacier (Local)...\")\n",
    "    glacier_local = _collect_glacier(GLACIER_ROOT, \"local\", glacier_meth)\n",
    "    print(\"Loading Glacier (Global)...\")\n",
    "    glacier_global = _collect_glacier(GLACIER_ROOT, \"global\", glacier_meth)\n",
    "\n",
    "    print(\"Loading CELS (Local)...\")\n",
    "    cels_local = _collect_cels(CELS_ROOT, \"local\")\n",
    "    print(\"Loading CELS (Global)...\")\n",
    "    cels_global = _collect_cels(CELS_ROOT, \"global\")\n",
    "\n",
    "    print(\"Loading RSF (Local)...\")\n",
    "    rsf_local = _collect_rsf(RSF_ROOT, \"local\")\n",
    "    print(\"Loading RSF (Global)...\")\n",
    "    rsf_global = _collect_rsf(RSF_ROOT, \"global\")\n",
    "\n",
    "    n = max(len(d) for d in [glacier_local, glacier_global, cels_local, cels_global, rsf_local, rsf_global] if d)\n",
    "\n",
    "    def _plot_cf(ax, item, title):\n",
    "        x0, xcf = np.squeeze(item[\"x0\"]), np.squeeze(item[\"xcf\"])\n",
    "        y_true, y0, ycf, tag = item[\"y_true\"], item[\"y0\"], item[\"ycf\"], item[\"tag\"]\n",
    "\n",
    "        delta = np.abs(xcf - x0)\n",
    "        changed = delta > THR\n",
    "        sparsity = np.mean(changed)\n",
    "        proximity = np.linalg.norm(x0 - xcf)\n",
    "        meaningful_cf = (y0 == y_true) and (y0 != ycf)\n",
    "\n",
    "        ax.plot(x0, lw=1, color=\"#d62728\", label=f\"Original (true={y_true}, pred={y0})\")\n",
    "        ax.plot(xcf, lw=0.7, color=\"grey\", ls=\"--\", label=f\"CF (ŷ={ycf})\")\n",
    "        ax.fill_between(np.arange(len(x0)), 0, 1, where=changed, color=\"#ffdf88\", alpha=0.35)\n",
    "\n",
    "        note = \" [Meaningful CF]\" if meaningful_cf else \"\"\n",
    "        ax.set_title(\n",
    "            f\"{title} | Sparsity: {sparsity:.1%} | Proximity: {proximity:.2f}{note}\\n(Source: {tag})\",\n",
    "            fontsize=10\n",
    "        )\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    def _show(idx=0):\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(16, 12), sharex=True)\n",
    "        layout = [\n",
    "            (\"Glacier GLOBAL\", glacier_global, \"Glacier LOCAL\", glacier_local),\n",
    "            (\"CELS GLOBAL\", cels_global, \"CELS LOCAL\", cels_local),\n",
    "            (\"RSF GLOBAL\", rsf_global, \"RSF LOCAL\", rsf_local)\n",
    "        ]\n",
    "\n",
    "        for row, (gt, gdata, lt, ldata) in enumerate(layout):\n",
    "            axg, axl = axes[row, 0], axes[row, 1]\n",
    "            if gdata:\n",
    "                _plot_cf(axg, gdata[idx % len(gdata)], gt)\n",
    "            else:\n",
    "                axg.set_title(f\"{gt} - No data found\", fontsize=10)\n",
    "                axg.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", style=\"italic\")\n",
    "            if ldata:\n",
    "                _plot_cf(axl, ldata[idx % len(ldata)], lt)\n",
    "            else:\n",
    "                axl.set_title(f\"{lt} - No data found\", fontsize=10)\n",
    "                axl.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", style=\"italic\")\n",
    "\n",
    "        axes[2, 0].set_xlabel(\"Spectral Index\")\n",
    "        axes[2, 1].set_xlabel(\"Spectral Index\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    interact(_show, idx=IntSlider(0, 0, n - 1, 1, description=\"Sample Index\", continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e379d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glacier CNN (Local)...\n",
      "Loading Glacier CNN (Global)...\n",
      "Loading Glacier NE (Local)...\n",
      "Loading Glacier NE (Global)...\n",
      "Loading CELS (Local)...\n",
      "Loading CELS (Global)...\n",
      "Loading RSF (Local)...\n",
      "Loading RSF (Global)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d520b39f6b45058e3e9429fb72615d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample Index', max=499), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glacier CNN (Local)...\n",
      "Loading Glacier CNN (Global)...\n",
      "Loading Glacier NE (Local)...\n",
      "Loading Glacier NE (Global)...\n",
      "Loading CELS (Local)...\n",
      "Loading CELS (Global)...\n",
      "Loading RSF (Local)...\n",
      "Loading RSF (Global)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7de5124e1ba47d68044fe6cb0f35355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample Index', max=308), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glacier CNN (Local)...\n",
      "Loading Glacier CNN (Global)...\n",
      "Loading Glacier NE (Local)...\n",
      "Loading Glacier NE (Global)...\n",
      "Loading CELS (Local)...\n",
      "Loading CELS (Global)...\n",
      "Loading RSF (Local)...\n",
      "Loading RSF (Global)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cc600222794814a5fe6af2569f4439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample Index', max=499), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(dataset_name=\"EcoliVsKpneumoniae_ramanspy_singular\")\n",
    "view(dataset_name=\"RamanCOVID19_ramanspy_preprocessed\")\n",
    "view(dataset_name=\"DRS_TissueClassification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a93c3",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011dadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def per_sample_metrics(x0, xcf, y0, ycf, thr):\n",
    "    x0 = np.asarray(x0).ravel()\n",
    "    xcf = np.asarray(xcf).ravel()\n",
    "    delta = xcf - x0\n",
    "    \n",
    "    l2_abs = float(np.linalg.norm(delta))\n",
    "    l2_rel = float(l2_abs / (np.linalg.norm(x0) + 1e-12))\n",
    "    sparsity = float(np.mean(np.abs(delta) > thr))\n",
    "    validity = int(int(ycf) != int(y0))\n",
    "    \n",
    "    return l2_abs, l2_rel, sparsity, validity\n",
    "\n",
    "def calculate_and_display_metrics(dataset_name, threshold=0.025):\n",
    "    print(f\"--- Calculating Metrics for: {dataset_name} ---\")\n",
    "    \n",
    "    GLACIER_ROOT = Path(\"Glacier/learning-time-series-counterfactuals/cf_runs\") / dataset_name\n",
    "    CELS_ROOT = Path(\"CELS/CELS/cf_runs\") / dataset_name\n",
    "    RSF_ROOT = Path(\"RSF/RSF/cf_runs\") / dataset_name\n",
    "\n",
    "    all_sets = {\n",
    "        \"Glacier_cnn_local\": _collect_glacier(GLACIER_ROOT, \"local\", \"cnn\"),\n",
    "        \"Glacier_cnn_global\": _collect_glacier(GLACIER_ROOT, \"global\", \"cnn\"),\n",
    "        \"Glacier_ne_local\": _collect_glacier(GLACIER_ROOT, \"local\", \"ne\"),\n",
    "        \"Glacier_ne_global\": _collect_glacier(GLACIER_ROOT, \"global\", \"ne\"),\n",
    "        \"CELS_local\": _collect_cels(CELS_ROOT, \"local\"),\n",
    "        \"CELS_global\": _collect_cels(CELS_ROOT, \"global\"),\n",
    "        \"RSF_local\": _collect_rsf(RSF_ROOT, \"local\"),\n",
    "        \"RSF_global\": _collect_rsf(RSF_ROOT, \"global\"),\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for name, items in all_sets.items():\n",
    "        if not items:\n",
    "            print(f\"No '{name}', skipping.\")\n",
    "            continue\n",
    "            \n",
    "        for it in items:\n",
    "            l2_abs, l2_rel, spars, valid = per_sample_metrics(it[\"x0\"], it[\"xcf\"], it[\"y0\"], it[\"ycf\"], threshold)\n",
    "            rows.append({\n",
    "                \"Method\": name,\n",
    "                \"proximity_abs\": l2_abs,\n",
    "                \"proximity_rel\": l2_rel,\n",
    "                \"sparsity\": spars,\n",
    "                \"validity\": valid,\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    agg = df.groupby(\"Method\").agg(\n",
    "        N=(\"validity\", \"size\"),\n",
    "        **{\n",
    "            \"Avg Rel Proximity\": (\"proximity_rel\", \"mean\"),\n",
    "            \"Std Rel Proximity\": (\"proximity_rel\", \"std\"),\n",
    "            \"Median Rel Proximity\": (\"proximity_rel\", \"median\"),\n",
    "            \"Avg Sparsity\": (\"sparsity\", \"mean\"),\n",
    "            \"Std Sparsity\": (\"sparsity\", \"std\"),\n",
    "            \"Median Sparsity\": (\"sparsity\", \"median\"),\n",
    "            \"Validity\": (\"validity\", \"mean\"),\n",
    "        }\n",
    "    ).reset_index()\n",
    "\n",
    "    pretty = agg.copy()\n",
    "    pretty[\"Avg Rel Proximity\"] = pretty[\"Avg Rel Proximity\"].round(4)\n",
    "    pretty[\"Std Rel Proximity\"] = pretty[\"Std Rel Proximity\"].round(4)\n",
    "    pretty[\"Median Rel Proximity\"] = pretty[\"Median Rel Proximity\"].round(4)\n",
    "    pretty[\"Avg Sparsity\"] = (pretty[\"Avg Sparsity\"] * 100).round(2).astype(str) + \"%\"\n",
    "    pretty[\"Std Sparsity\"] = (pretty[\"Std Sparsity\"] * 100).round(2).astype(str) + \"%\"\n",
    "    pretty[\"Median Sparsity\"] = (pretty[\"Median Sparsity\"] * 100).round(2).astype(str) + \"%\"\n",
    "    pretty[\"Validity\"] = (pretty[\"Validity\"] * 100).round(2).astype(str) + \"%\"\n",
    "\n",
    "    print(\"\\n--- Aggregated Results ---\")\n",
    "    display(pretty.style.hide(axis='index'))\n",
    "    return agg\n",
    "\n",
    "def compare_methods_statistical(dataset_name, threshold=0.025):\n",
    "    \"\"\"Additional function to provide statistical comparisons between methods\"\"\"\n",
    "    print(f\"--- Statistical Comparison for: {dataset_name} ---\")\n",
    "\n",
    "    # Get raw aggregated data\n",
    "    agg = calculate_and_display_metrics(dataset_name, threshold)\n",
    "\n",
    "    if agg is None:\n",
    "        return\n",
    "    # Find best performing methods for each metric\n",
    "    print(\"\\n--- Best Performers ---\")\n",
    "    best_validity = agg.loc[agg['Validity'].idxmax()]\n",
    "    print(f\"Best Validity: {best_validity['Method']} ({best_validity['Validity']:.1%})\")\n",
    "\n",
    "    best_proximity = agg.loc[agg['Avg Rel Proximity'].idxmin()]\n",
    "    print(f\"Best Proximity: {best_proximity['Method']} ({best_proximity['Avg Rel Proximity']:.4f})\")\n",
    "\n",
    "    best_sparsity = agg.loc[agg['Avg Sparsity'].idxmin()]\n",
    "    print(f\"Best Sparsity: {best_sparsity['Method']} ({best_sparsity['Avg Sparsity']:.1%})\")\n",
    "\n",
    "    #return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9093c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Statistical Comparison for: DRS_TissueClassification ---\n",
      "--- Calculating Metrics for: DRS_TissueClassification ---\n",
      "\n",
      "--- Aggregated Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_06df1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_06df1_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_06df1_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_06df1_level0_col2\" class=\"col_heading level0 col2\" >Avg Rel Proximity</th>\n",
       "      <th id=\"T_06df1_level0_col3\" class=\"col_heading level0 col3\" >Std Rel Proximity</th>\n",
       "      <th id=\"T_06df1_level0_col4\" class=\"col_heading level0 col4\" >Median Rel Proximity</th>\n",
       "      <th id=\"T_06df1_level0_col5\" class=\"col_heading level0 col5\" >Avg Sparsity</th>\n",
       "      <th id=\"T_06df1_level0_col6\" class=\"col_heading level0 col6\" >Std Sparsity</th>\n",
       "      <th id=\"T_06df1_level0_col7\" class=\"col_heading level0 col7\" >Median Sparsity</th>\n",
       "      <th id=\"T_06df1_level0_col8\" class=\"col_heading level0 col8\" >Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_06df1_row0_col0\" class=\"data row0 col0\" >CELS_global</td>\n",
       "      <td id=\"T_06df1_row0_col1\" class=\"data row0 col1\" >500</td>\n",
       "      <td id=\"T_06df1_row0_col2\" class=\"data row0 col2\" >0.074100</td>\n",
       "      <td id=\"T_06df1_row0_col3\" class=\"data row0 col3\" >0.029000</td>\n",
       "      <td id=\"T_06df1_row0_col4\" class=\"data row0 col4\" >0.070200</td>\n",
       "      <td id=\"T_06df1_row0_col5\" class=\"data row0 col5\" >31.99%</td>\n",
       "      <td id=\"T_06df1_row0_col6\" class=\"data row0 col6\" >10.2%</td>\n",
       "      <td id=\"T_06df1_row0_col7\" class=\"data row0 col7\" >32.4%</td>\n",
       "      <td id=\"T_06df1_row0_col8\" class=\"data row0 col8\" >99.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_06df1_row1_col0\" class=\"data row1 col0\" >CELS_local</td>\n",
       "      <td id=\"T_06df1_row1_col1\" class=\"data row1 col1\" >500</td>\n",
       "      <td id=\"T_06df1_row1_col2\" class=\"data row1 col2\" >0.028200</td>\n",
       "      <td id=\"T_06df1_row1_col3\" class=\"data row1 col3\" >0.016900</td>\n",
       "      <td id=\"T_06df1_row1_col4\" class=\"data row1 col4\" >0.028100</td>\n",
       "      <td id=\"T_06df1_row1_col5\" class=\"data row1 col5\" >3.34%</td>\n",
       "      <td id=\"T_06df1_row1_col6\" class=\"data row1 col6\" >2.52%</td>\n",
       "      <td id=\"T_06df1_row1_col7\" class=\"data row1 col7\" >2.78%</td>\n",
       "      <td id=\"T_06df1_row1_col8\" class=\"data row1 col8\" >48.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_06df1_row2_col0\" class=\"data row2 col0\" >Glacier_global</td>\n",
       "      <td id=\"T_06df1_row2_col1\" class=\"data row2 col1\" >500</td>\n",
       "      <td id=\"T_06df1_row2_col2\" class=\"data row2 col2\" >0.049600</td>\n",
       "      <td id=\"T_06df1_row2_col3\" class=\"data row2 col3\" >0.016300</td>\n",
       "      <td id=\"T_06df1_row2_col4\" class=\"data row2 col4\" >0.046000</td>\n",
       "      <td id=\"T_06df1_row2_col5\" class=\"data row2 col5\" >16.97%</td>\n",
       "      <td id=\"T_06df1_row2_col6\" class=\"data row2 col6\" >3.49%</td>\n",
       "      <td id=\"T_06df1_row2_col7\" class=\"data row2 col7\" >16.92%</td>\n",
       "      <td id=\"T_06df1_row2_col8\" class=\"data row2 col8\" >99.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_06df1_row3_col0\" class=\"data row3 col0\" >Glacier_local</td>\n",
       "      <td id=\"T_06df1_row3_col1\" class=\"data row3 col1\" >500</td>\n",
       "      <td id=\"T_06df1_row3_col2\" class=\"data row3 col2\" >0.055600</td>\n",
       "      <td id=\"T_06df1_row3_col3\" class=\"data row3 col3\" >0.018900</td>\n",
       "      <td id=\"T_06df1_row3_col4\" class=\"data row3 col4\" >0.053600</td>\n",
       "      <td id=\"T_06df1_row3_col5\" class=\"data row3 col5\" >24.49%</td>\n",
       "      <td id=\"T_06df1_row3_col6\" class=\"data row3 col6\" >16.51%</td>\n",
       "      <td id=\"T_06df1_row3_col7\" class=\"data row3 col7\" >18.06%</td>\n",
       "      <td id=\"T_06df1_row3_col8\" class=\"data row3 col8\" >98.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_06df1_row4_col0\" class=\"data row4 col0\" >RSF_global</td>\n",
       "      <td id=\"T_06df1_row4_col1\" class=\"data row4 col1\" >1250</td>\n",
       "      <td id=\"T_06df1_row4_col2\" class=\"data row4 col2\" >0.134300</td>\n",
       "      <td id=\"T_06df1_row4_col3\" class=\"data row4 col3\" >0.048500</td>\n",
       "      <td id=\"T_06df1_row4_col4\" class=\"data row4 col4\" >0.136700</td>\n",
       "      <td id=\"T_06df1_row4_col5\" class=\"data row4 col5\" >9.82%</td>\n",
       "      <td id=\"T_06df1_row4_col6\" class=\"data row4 col6\" >0.62%</td>\n",
       "      <td id=\"T_06df1_row4_col7\" class=\"data row4 col7\" >9.99%</td>\n",
       "      <td id=\"T_06df1_row4_col8\" class=\"data row4 col8\" >55.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_06df1_row5_col0\" class=\"data row5 col0\" >RSF_local</td>\n",
       "      <td id=\"T_06df1_row5_col1\" class=\"data row5 col1\" >1250</td>\n",
       "      <td id=\"T_06df1_row5_col2\" class=\"data row5 col2\" >0.081900</td>\n",
       "      <td id=\"T_06df1_row5_col3\" class=\"data row5 col3\" >0.032100</td>\n",
       "      <td id=\"T_06df1_row5_col4\" class=\"data row5 col4\" >0.080300</td>\n",
       "      <td id=\"T_06df1_row5_col5\" class=\"data row5 col5\" >45.92%</td>\n",
       "      <td id=\"T_06df1_row5_col6\" class=\"data row5 col6\" >17.38%</td>\n",
       "      <td id=\"T_06df1_row5_col7\" class=\"data row5 col7\" >47.39%</td>\n",
       "      <td id=\"T_06df1_row5_col8\" class=\"data row5 col8\" >98.88%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f864591b110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Performers ---\n",
      "Best Validity: Glacier_global (99.4%)\n",
      "Best Proximity: CELS_local (0.0282)\n",
      "Best Sparsity: CELS_local (3.3%)\n",
      "--- Statistical Comparison for: EcoliVsKpneumoniae_ramanspy_singular ---\n",
      "--- Calculating Metrics for: EcoliVsKpneumoniae_ramanspy_singular ---\n",
      "\n",
      "--- Aggregated Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_61d4d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_61d4d_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_61d4d_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_61d4d_level0_col2\" class=\"col_heading level0 col2\" >Avg Rel Proximity</th>\n",
       "      <th id=\"T_61d4d_level0_col3\" class=\"col_heading level0 col3\" >Std Rel Proximity</th>\n",
       "      <th id=\"T_61d4d_level0_col4\" class=\"col_heading level0 col4\" >Median Rel Proximity</th>\n",
       "      <th id=\"T_61d4d_level0_col5\" class=\"col_heading level0 col5\" >Avg Sparsity</th>\n",
       "      <th id=\"T_61d4d_level0_col6\" class=\"col_heading level0 col6\" >Std Sparsity</th>\n",
       "      <th id=\"T_61d4d_level0_col7\" class=\"col_heading level0 col7\" >Median Sparsity</th>\n",
       "      <th id=\"T_61d4d_level0_col8\" class=\"col_heading level0 col8\" >Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_61d4d_row0_col0\" class=\"data row0 col0\" >CELS_global</td>\n",
       "      <td id=\"T_61d4d_row0_col1\" class=\"data row0 col1\" >500</td>\n",
       "      <td id=\"T_61d4d_row0_col2\" class=\"data row0 col2\" >0.094900</td>\n",
       "      <td id=\"T_61d4d_row0_col3\" class=\"data row0 col3\" >0.013100</td>\n",
       "      <td id=\"T_61d4d_row0_col4\" class=\"data row0 col4\" >0.092900</td>\n",
       "      <td id=\"T_61d4d_row0_col5\" class=\"data row0 col5\" >18.95%</td>\n",
       "      <td id=\"T_61d4d_row0_col6\" class=\"data row0 col6\" >1.79%</td>\n",
       "      <td id=\"T_61d4d_row0_col7\" class=\"data row0 col7\" >18.8%</td>\n",
       "      <td id=\"T_61d4d_row0_col8\" class=\"data row0 col8\" >25.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61d4d_row1_col0\" class=\"data row1 col0\" >CELS_local</td>\n",
       "      <td id=\"T_61d4d_row1_col1\" class=\"data row1 col1\" >500</td>\n",
       "      <td id=\"T_61d4d_row1_col2\" class=\"data row1 col2\" >0.140800</td>\n",
       "      <td id=\"T_61d4d_row1_col3\" class=\"data row1 col3\" >0.023500</td>\n",
       "      <td id=\"T_61d4d_row1_col4\" class=\"data row1 col4\" >0.143900</td>\n",
       "      <td id=\"T_61d4d_row1_col5\" class=\"data row1 col5\" >10.91%</td>\n",
       "      <td id=\"T_61d4d_row1_col6\" class=\"data row1 col6\" >4.59%</td>\n",
       "      <td id=\"T_61d4d_row1_col7\" class=\"data row1 col7\" >10.7%</td>\n",
       "      <td id=\"T_61d4d_row1_col8\" class=\"data row1 col8\" >76.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61d4d_row2_col0\" class=\"data row2 col0\" >Glacier_global</td>\n",
       "      <td id=\"T_61d4d_row2_col1\" class=\"data row2 col1\" >500</td>\n",
       "      <td id=\"T_61d4d_row2_col2\" class=\"data row2 col2\" >0.076700</td>\n",
       "      <td id=\"T_61d4d_row2_col3\" class=\"data row2 col3\" >0.015100</td>\n",
       "      <td id=\"T_61d4d_row2_col4\" class=\"data row2 col4\" >0.074400</td>\n",
       "      <td id=\"T_61d4d_row2_col5\" class=\"data row2 col5\" >17.21%</td>\n",
       "      <td id=\"T_61d4d_row2_col6\" class=\"data row2 col6\" >3.67%</td>\n",
       "      <td id=\"T_61d4d_row2_col7\" class=\"data row2 col7\" >16.3%</td>\n",
       "      <td id=\"T_61d4d_row2_col8\" class=\"data row2 col8\" >98.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61d4d_row3_col0\" class=\"data row3 col0\" >Glacier_local</td>\n",
       "      <td id=\"T_61d4d_row3_col1\" class=\"data row3 col1\" >500</td>\n",
       "      <td id=\"T_61d4d_row3_col2\" class=\"data row3 col2\" >0.069000</td>\n",
       "      <td id=\"T_61d4d_row3_col3\" class=\"data row3 col3\" >0.016600</td>\n",
       "      <td id=\"T_61d4d_row3_col4\" class=\"data row3 col4\" >0.066200</td>\n",
       "      <td id=\"T_61d4d_row3_col5\" class=\"data row3 col5\" >16.7%</td>\n",
       "      <td id=\"T_61d4d_row3_col6\" class=\"data row3 col6\" >5.97%</td>\n",
       "      <td id=\"T_61d4d_row3_col7\" class=\"data row3 col7\" >16.0%</td>\n",
       "      <td id=\"T_61d4d_row3_col8\" class=\"data row3 col8\" >98.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61d4d_row4_col0\" class=\"data row4 col0\" >RSF_global</td>\n",
       "      <td id=\"T_61d4d_row4_col1\" class=\"data row4 col1\" >1250</td>\n",
       "      <td id=\"T_61d4d_row4_col2\" class=\"data row4 col2\" >0.101800</td>\n",
       "      <td id=\"T_61d4d_row4_col3\" class=\"data row4 col3\" >0.021400</td>\n",
       "      <td id=\"T_61d4d_row4_col4\" class=\"data row4 col4\" >0.098400</td>\n",
       "      <td id=\"T_61d4d_row4_col5\" class=\"data row4 col5\" >8.72%</td>\n",
       "      <td id=\"T_61d4d_row4_col6\" class=\"data row4 col6\" >0.54%</td>\n",
       "      <td id=\"T_61d4d_row4_col7\" class=\"data row4 col7\" >8.7%</td>\n",
       "      <td id=\"T_61d4d_row4_col8\" class=\"data row4 col8\" >7.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61d4d_row5_col0\" class=\"data row5 col0\" >RSF_local</td>\n",
       "      <td id=\"T_61d4d_row5_col1\" class=\"data row5 col1\" >1250</td>\n",
       "      <td id=\"T_61d4d_row5_col2\" class=\"data row5 col2\" >0.072300</td>\n",
       "      <td id=\"T_61d4d_row5_col3\" class=\"data row5 col3\" >0.036600</td>\n",
       "      <td id=\"T_61d4d_row5_col4\" class=\"data row5 col4\" >0.078500</td>\n",
       "      <td id=\"T_61d4d_row5_col5\" class=\"data row5 col5\" >30.53%</td>\n",
       "      <td id=\"T_61d4d_row5_col6\" class=\"data row5 col6\" >17.38%</td>\n",
       "      <td id=\"T_61d4d_row5_col7\" class=\"data row5 col7\" >33.95%</td>\n",
       "      <td id=\"T_61d4d_row5_col8\" class=\"data row5 col8\" >82.72%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f86453a15d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Performers ---\n",
      "Best Validity: Glacier_global (98.8%)\n",
      "Best Proximity: Glacier_local (0.0690)\n",
      "Best Sparsity: RSF_global (8.7%)\n",
      "--- Statistical Comparison for: RamanCOVID19_ramanspy_preprocessed ---\n",
      "--- Calculating Metrics for: RamanCOVID19_ramanspy_preprocessed ---\n",
      "\n",
      "--- Aggregated Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ff2bc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_ff2bc_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_ff2bc_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_ff2bc_level0_col2\" class=\"col_heading level0 col2\" >Avg Rel Proximity</th>\n",
       "      <th id=\"T_ff2bc_level0_col3\" class=\"col_heading level0 col3\" >Std Rel Proximity</th>\n",
       "      <th id=\"T_ff2bc_level0_col4\" class=\"col_heading level0 col4\" >Median Rel Proximity</th>\n",
       "      <th id=\"T_ff2bc_level0_col5\" class=\"col_heading level0 col5\" >Avg Sparsity</th>\n",
       "      <th id=\"T_ff2bc_level0_col6\" class=\"col_heading level0 col6\" >Std Sparsity</th>\n",
       "      <th id=\"T_ff2bc_level0_col7\" class=\"col_heading level0 col7\" >Median Sparsity</th>\n",
       "      <th id=\"T_ff2bc_level0_col8\" class=\"col_heading level0 col8\" >Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_ff2bc_row0_col0\" class=\"data row0 col0\" >CELS_global</td>\n",
       "      <td id=\"T_ff2bc_row0_col1\" class=\"data row0 col1\" >309</td>\n",
       "      <td id=\"T_ff2bc_row0_col2\" class=\"data row0 col2\" >0.086200</td>\n",
       "      <td id=\"T_ff2bc_row0_col3\" class=\"data row0 col3\" >0.046100</td>\n",
       "      <td id=\"T_ff2bc_row0_col4\" class=\"data row0 col4\" >0.068700</td>\n",
       "      <td id=\"T_ff2bc_row0_col5\" class=\"data row0 col5\" >8.61%</td>\n",
       "      <td id=\"T_ff2bc_row0_col6\" class=\"data row0 col6\" >8.42%</td>\n",
       "      <td id=\"T_ff2bc_row0_col7\" class=\"data row0 col7\" >5.22%</td>\n",
       "      <td id=\"T_ff2bc_row0_col8\" class=\"data row0 col8\" >60.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff2bc_row1_col0\" class=\"data row1 col0\" >CELS_local</td>\n",
       "      <td id=\"T_ff2bc_row1_col1\" class=\"data row1 col1\" >349</td>\n",
       "      <td id=\"T_ff2bc_row1_col2\" class=\"data row1 col2\" >0.048000</td>\n",
       "      <td id=\"T_ff2bc_row1_col3\" class=\"data row1 col3\" >0.042300</td>\n",
       "      <td id=\"T_ff2bc_row1_col4\" class=\"data row1 col4\" >0.032700</td>\n",
       "      <td id=\"T_ff2bc_row1_col5\" class=\"data row1 col5\" >2.13%</td>\n",
       "      <td id=\"T_ff2bc_row1_col6\" class=\"data row1 col6\" >2.61%</td>\n",
       "      <td id=\"T_ff2bc_row1_col7\" class=\"data row1 col7\" >1.44%</td>\n",
       "      <td id=\"T_ff2bc_row1_col8\" class=\"data row1 col8\" >69.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff2bc_row2_col0\" class=\"data row2 col0\" >Glacier_global</td>\n",
       "      <td id=\"T_ff2bc_row2_col1\" class=\"data row2 col1\" >309</td>\n",
       "      <td id=\"T_ff2bc_row2_col2\" class=\"data row2 col2\" >0.358600</td>\n",
       "      <td id=\"T_ff2bc_row2_col3\" class=\"data row2 col3\" >0.043000</td>\n",
       "      <td id=\"T_ff2bc_row2_col4\" class=\"data row2 col4\" >0.352400</td>\n",
       "      <td id=\"T_ff2bc_row2_col5\" class=\"data row2 col5\" >18.33%</td>\n",
       "      <td id=\"T_ff2bc_row2_col6\" class=\"data row2 col6\" >1.27%</td>\n",
       "      <td id=\"T_ff2bc_row2_col7\" class=\"data row2 col7\" >18.56%</td>\n",
       "      <td id=\"T_ff2bc_row2_col8\" class=\"data row2 col8\" >100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff2bc_row3_col0\" class=\"data row3 col0\" >Glacier_local</td>\n",
       "      <td id=\"T_ff2bc_row3_col1\" class=\"data row3 col1\" >309</td>\n",
       "      <td id=\"T_ff2bc_row3_col2\" class=\"data row3 col2\" >0.398100</td>\n",
       "      <td id=\"T_ff2bc_row3_col3\" class=\"data row3 col3\" >0.102900</td>\n",
       "      <td id=\"T_ff2bc_row3_col4\" class=\"data row3 col4\" >0.438500</td>\n",
       "      <td id=\"T_ff2bc_row3_col5\" class=\"data row3 col5\" >18.1%</td>\n",
       "      <td id=\"T_ff2bc_row3_col6\" class=\"data row3 col6\" >7.28%</td>\n",
       "      <td id=\"T_ff2bc_row3_col7\" class=\"data row3 col7\" >20.56%</td>\n",
       "      <td id=\"T_ff2bc_row3_col8\" class=\"data row3 col8\" >100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff2bc_row4_col0\" class=\"data row4 col0\" >RSF_global</td>\n",
       "      <td id=\"T_ff2bc_row4_col1\" class=\"data row4 col1\" >309</td>\n",
       "      <td id=\"T_ff2bc_row4_col2\" class=\"data row4 col2\" >0.096900</td>\n",
       "      <td id=\"T_ff2bc_row4_col3\" class=\"data row4 col3\" >0.043600</td>\n",
       "      <td id=\"T_ff2bc_row4_col4\" class=\"data row4 col4\" >0.083300</td>\n",
       "      <td id=\"T_ff2bc_row4_col5\" class=\"data row4 col5\" >5.52%</td>\n",
       "      <td id=\"T_ff2bc_row4_col6\" class=\"data row4 col6\" >2.22%</td>\n",
       "      <td id=\"T_ff2bc_row4_col7\" class=\"data row4 col7\" >5.56%</td>\n",
       "      <td id=\"T_ff2bc_row4_col8\" class=\"data row4 col8\" >72.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff2bc_row5_col0\" class=\"data row5 col0\" >RSF_local</td>\n",
       "      <td id=\"T_ff2bc_row5_col1\" class=\"data row5 col1\" >309</td>\n",
       "      <td id=\"T_ff2bc_row5_col2\" class=\"data row5 col2\" >0.110600</td>\n",
       "      <td id=\"T_ff2bc_row5_col3\" class=\"data row5 col3\" >0.050600</td>\n",
       "      <td id=\"T_ff2bc_row5_col4\" class=\"data row5 col4\" >0.113200</td>\n",
       "      <td id=\"T_ff2bc_row5_col5\" class=\"data row5 col5\" >12.86%</td>\n",
       "      <td id=\"T_ff2bc_row5_col6\" class=\"data row5 col6\" >10.16%</td>\n",
       "      <td id=\"T_ff2bc_row5_col7\" class=\"data row5 col7\" >11.67%</td>\n",
       "      <td id=\"T_ff2bc_row5_col8\" class=\"data row5 col8\" >89.32%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f864c6bb390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Performers ---\n",
      "Best Validity: Glacier_global (100.0%)\n",
      "Best Proximity: CELS_local (0.0480)\n",
      "Best Sparsity: CELS_local (2.1%)\n"
     ]
    }
   ],
   "source": [
    "compare_methods_statistical(\"DRS_TissueClassification\")\n",
    "compare_methods_statistical(\"EcoliVsKpneumoniae_ramanspy_singular\")\n",
    "compare_methods_statistical(\"RamanCOVID19_ramanspy_preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ea2d0",
   "metadata": {},
   "source": [
    "# Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56930cf2",
   "metadata": {},
   "source": [
    "### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26c97b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_glacier_concat(project_path: str, dataset_name: str, mode: str, method: str):\n",
    "    base = Path(project_path) / \"cf_runs\" / dataset_name / mode\n",
    "    files = sorted(base.glob(f\"cf_fold*_{method}.npz\"))\n",
    "    if not files:\n",
    "        print(f\"  [Glacier] No files for {mode}/{method} under {base}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    X0, XCF, YTRUE, YPRED, YCF = [], [], [], [], []\n",
    "    for f in files:\n",
    "        try:\n",
    "            with np.load(f, allow_pickle=True) as Z:\n",
    "                x0 = Z[\"x_orig\"]\n",
    "                xcf = Z[\"x_cf\"]\n",
    "                y_true = Z[\"y_true\"]\n",
    "                y_pred = Z[\"y_pred\"]\n",
    "                y_cf = Z[\"y_cf\"]\n",
    "                \n",
    "            n = min(len(x0), len(xcf), len(y_true), len(y_pred), len(y_cf))\n",
    "            X0.append(np.squeeze(x0[:n]))\n",
    "            XCF.append(np.squeeze(xcf[:n]))\n",
    "            YTRUE.append(y_true[:n])\n",
    "            YPRED.append(y_pred[:n])\n",
    "            YCF.append(y_cf[:n])\n",
    "            print(f\"  [Glacier] loaded {f.name}: {n} samples\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [Glacier] WARNING: could not load {f}: {e}\")\n",
    "\n",
    "    x_orig = np.concatenate(X0, axis=0)\n",
    "    x_cf = np.concatenate(XCF, axis=0)\n",
    "    y_true = np.concatenate(YTRUE, axis=0)\n",
    "    y_pred = np.concatenate(YPRED, axis=0)\n",
    "    y_cf = np.concatenate(YCF, axis=0)\n",
    "    print(f\"  [Glacier] concatenated {mode}/{method}: {len(x_orig)} samples total\")\n",
    "    return x_orig, x_cf, y_true, y_pred, y_cf\n",
    "\n",
    "\n",
    "def _load_cels_concat(project_path: str, dataset_name: str, mode: str):\n",
    "    base = Path(project_path) / \"cf_runs\" / dataset_name / mode\n",
    "    files = sorted(base.glob(\"cf_fold*.npz\"))\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"  [CELS] No files for {mode} under {base}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    X0, XCF, YTRUE, YPRED, YCF = [], [], [], [], []\n",
    "    for f in files:\n",
    "        try:\n",
    "            with np.load(f, allow_pickle=True) as Z:\n",
    "                x0 = Z[\"x0\"]\n",
    "                xcf = Z[\"xcf\"]\n",
    "                y_true = Z[\"y_true\"]\n",
    "                y_pred = Z[\"y_pred\"]\n",
    "                y_cf = Z[\"y_cf\"]\n",
    "            \n",
    "            n = min(len(x0), len(xcf), len(y_true), len(y_pred), len(y_cf))\n",
    "            if n > 0:\n",
    "                X0.append(np.squeeze(x0[:n]))\n",
    "                XCF.append(np.squeeze(xcf[:n]))\n",
    "                YTRUE.append(y_true[:n])\n",
    "                YPRED.append(y_pred[:n])\n",
    "                YCF.append(y_cf[:n])\n",
    "                print(f\"  [CELS] loaded {f.name}: {n} samples\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [CELS] WARNING: could not load {f}: {e}\")\n",
    "    \n",
    "    if not X0:\n",
    "        return None, None, None, None, None\n",
    "        \n",
    "    try:\n",
    "        x_orig = np.concatenate(X0, axis=0)\n",
    "        x_cf = np.concatenate(XCF, axis=0)\n",
    "        y_true = np.concatenate(YTRUE, axis=0)\n",
    "        y_pred = np.concatenate(YPRED, axis=0)\n",
    "        y_cf = np.concatenate(YCF, axis=0)\n",
    "        print(f\"  [CELS] concatenated {mode}: {len(x_orig)} samples total\")\n",
    "        return x_orig, x_cf, y_true, y_pred, y_cf\n",
    "    except Exception as e:\n",
    "        print(f\"  [CELS] ERROR concatenating data: {e}\")\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "\n",
    "def _load_rsf_concat(project_path: str, dataset_name: str, mode: str):\n",
    "    base = Path(project_path) / \"cf_runs\" / dataset_name / mode / \"rsf\"\n",
    "    \n",
    "    if not base.exists():\n",
    "        print(f\"  [RSF] Directory not found: {base}\")\n",
    "        return None, None, None, None, None\n",
    "        \n",
    "    files = sorted(base.glob(\"cf_fold*.npz\"))\n",
    "    if not files:\n",
    "        print(f\"  [RSF] No files for {mode} under {base}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    X0, XCF, YTRUE, YPRED, YCF = [], [], [], [], []\n",
    "    for f in files:\n",
    "        try:\n",
    "            with np.load(f, allow_pickle=False) as Z:\n",
    "                x0 = Z[\"x0\"]\n",
    "                xcf = Z[\"xcf\"]\n",
    "                y_true = Z[\"y_true\"]\n",
    "                y_pred = Z[\"y_pred\"]\n",
    "                y_cf = Z[\"y_cf\"]\n",
    "                \n",
    "            n = min(len(x0), len(xcf), len(y_true), len(y_pred), len(y_cf))\n",
    "            if n > 0:  \n",
    "                X0.append(np.squeeze(x0[:n]))\n",
    "                XCF.append(np.squeeze(xcf[:n]))\n",
    "                YTRUE.append(y_true[:n])\n",
    "                YPRED.append(y_pred[:n])\n",
    "                YCF.append(y_cf[:n])\n",
    "                print(f\"  [RSF] loaded {f.name}: {n} samples\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [RSF] WARNING: could not load {f}: {e}\")\n",
    "\n",
    "    if not X0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    try:\n",
    "        x_orig = np.concatenate(X0, axis=0)\n",
    "        x_cf = np.concatenate(XCF, axis=0)\n",
    "        y_true = np.concatenate(YTRUE, axis=0)\n",
    "        y_pred = np.concatenate(YPRED, axis=0)\n",
    "        y_cf = np.concatenate(YCF, axis=0)\n",
    "        print(f\"  [RSF] concatenated {mode}: {len(x_orig)} samples total\")\n",
    "        return x_orig, x_cf, y_true, y_pred, y_cf\n",
    "    except Exception as e:\n",
    "        print(f\"  [RSF] ERROR concatenating data: {e}\")\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab433376",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ramanspy\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from IPython.display import display\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "def run_multiclass_evaluation(dataset_name, use_ramanspy_preprocessing=False, \n",
    "                             perform_gridsearch=True, quick_search=False):\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Running Multi-Class Evaluation for: {dataset_name}\")\n",
    "    if use_ramanspy_preprocessing:\n",
    "        print(\"Preprocessing Mode: ramanspy\")\n",
    "    if perform_gridsearch:\n",
    "        print(\"Hyperparameter Tuning: GridSearchCV enabled\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Configd\n",
    "    DATASET_CONFIGS = {\n",
    "        \"EcoliVsKpneumoniae_ramanspy_singular\": {\n",
    "            \"classes_to_use\": [0, 1, 2, 3, 9], #'C. albicans', 'C. glabrata', 'K. aerogenes'\n",
    "            \"bin2orig\": {1: {3}, 0: {9}}, #E.coli:3,4 K.pneumoniae:9,10\n",
    "            \"class_names\": {0: \"C.albicans\", 1: \"C.glabrata\", 2: \"K.aerogenes\", \n",
    "                           3: \"E.coli_1\", 4: \"E.coli_2\", 9: \"K.pneum_1\", 10: \"K.pneum_2\"}\n",
    "        },\n",
    "\n",
    "        \"RamanCOVID19_ramanspy_preprocessed\": {\n",
    "        \"classes_to_use\": [0, 1, 2],\n",
    "        \"bin2orig\": {1: {1}, 0: {0}},\n",
    "        \"class_names\": {0: \"Healthy\", 1: \"COVID-19\", 2: \"Suspected\"}\n",
    "        },\n",
    "\n",
    "        \"DRS_TissueClassification\": {\n",
    "            \"classes_to_use\": [0, 1, 2, 3, 4, 5],  # All 6 tissue classes\n",
    "            \"bin2orig\": {\n",
    "                1: {1},  # cortBone\n",
    "                0: {0}  # muscle\n",
    "            },\n",
    "            \"class_names\": {0: \"muscle\", 1: \"cortBone\", 2: \"traBone\", 3: \"cartilage\", 4: \"boneMarrow\", 5: \"boneCement\"}\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    if dataset_name not in DATASET_CONFIGS:\n",
    "        print(f\"ERROR: No configuration found for dataset '{dataset_name}'. Please add it to DATASET_CONFIGS.\")\n",
    "        return\n",
    "\n",
    "    config = DATASET_CONFIGS[dataset_name]\n",
    "    BIN2ORIG = config[\"bin2orig\"]\n",
    "    CLASS_NAMES = config.get(\"class_names\", {})\n",
    "    OUT_CSV = Path(f\"multiclass_metrics_{dataset_name}.csv\")\n",
    "\n",
    "    # Load reference data\n",
    "    print(\"Loading reference spectra...\")\n",
    "    RAMAN_DIR = Path.home() / \"data\" / \"raman\"\n",
    "    \n",
    "    if dataset_name in [\"RamanCOVID19\", \"RamanCOVID19_ramanspy_preprocessed\"]:\n",
    "        if dataset_name == \"RamanCOVID19\":\n",
    "            csv_path = Path(\"/home/cok7/local-datasets/covid19/covid19_serum_raman.csv\")\n",
    "        else: \n",
    "            csv_path = Path(\"/home/cok7/local-datasets/covid19/covid19_serum_raman_preprocessed.csv\")\n",
    "        \n",
    "        df = pd.read_csv(csv_path)\n",
    "        y_names = df[\"diagnostic\"].astype(str)\n",
    "        name2id = {\"Healthy\": 0, \"COVID-19\": 1, \"Suspected\": 2}\n",
    "        y_all = y_names.map(name2id).to_numpy(np.int64)\n",
    "        X_all = df.drop(columns=[\"diagnostic\"]).to_numpy(np.float32)\n",
    "\n",
    "    elif dataset_name == \"DRS_TissueClassification\":\n",
    "        csv_path = Path(\"/home/cok7/local-datasets/drs_tissue.csv\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        y_names = df[\"tissue_type\"].astype(str)\n",
    "        \n",
    "        # Map all tissue types to numeric classes\n",
    "        name2id = {\n",
    "            \"muscle\": 0, \n",
    "            \"cortBone\": 1, \n",
    "            \"traBone\": 2, \n",
    "            \"cartilage\": 3, \n",
    "            \"boneMarrow\": 4, \n",
    "            \"boneCement\": 5\n",
    "        }\n",
    "        \n",
    "        y_all = df[\"tissue_type\"].map(name2id).to_numpy(np.int64)\n",
    "        X_all = df.drop(columns=[\"tissue_type\"]).to_numpy(np.float32)\n",
    "        print(f\"DRS tissue distribution: {dict(zip(*np.unique(y_all, return_counts=True)))}\")\n",
    "        \n",
    "    else:\n",
    "        X_all = np.load(RAMAN_DIR / \"X_reference.npy\")\n",
    "        y_all = np.load(RAMAN_DIR / \"y_reference.npy\")\n",
    "\n",
    "    print(f\"Loaded reference data: X_all.shape={X_all.shape}, y_all.shape={y_all.shape}\")\n",
    "    print(f\"Unique classes in reference: {np.unique(y_all)}\")\n",
    "\n",
    "    # Apply preprocessing\n",
    "    if use_ramanspy_preprocessing:\n",
    "        print(\"Applying ramanspy preprocessing to reference data...\")\n",
    "        try:\n",
    "            raman_spectra = ramanspy.Spectrum(X_all, np.arange(X_all.shape[1]))\n",
    "            \n",
    "            pipeline = ramanspy.preprocessing.Pipeline([\n",
    "                ramanspy.preprocessing.despike.WhitakerHayes(),\n",
    "                ramanspy.preprocessing.baseline.ASLS(),\n",
    "                ramanspy.preprocessing.normalise.MinMax(),\n",
    "            ])\n",
    "            \n",
    "            preprocessed_spectra = pipeline.apply(raman_spectra)\n",
    "            X_all = preprocessed_spectra.spectral_data \n",
    "            print(\"Preprocessing completed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Preprocessing failed: {e}\")\n",
    "            print(\"Continuing with unprocessed data...\")\n",
    "\n",
    "    # Filter to relevant classes\n",
    "    mask = np.isin(y_all, config[\"classes_to_use\"])\n",
    "    X_sub, y_sub = X_all[mask].astype(np.float32), y_all[mask]\n",
    "    \n",
    "    print(f\"After filtering to relevant classes: X_sub.shape={X_sub.shape}\")\n",
    "    print(f\"Class distribution: {dict(zip(*np.unique(y_sub, return_counts=True)))}\")\n",
    "\n",
    "    if len(X_sub) == 0:\n",
    "        print(\"ERROR: No samples found for the specified classes!\")\n",
    "        return None\n",
    "\n",
    "    # Train/test split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X_sub, y_sub, test_size=0.20, stratify=y_sub, random_state=4\n",
    "    )\n",
    "\n",
    "    # Train SVM model\n",
    "    print(f\"\\n--- Training SVM ---\")\n",
    "    \n",
    "    if perform_gridsearch:\n",
    "        print(f\"Performing hyperparameter tuning for SVM...\")\n",
    "        \n",
    "        if quick_search:\n",
    "            param_grid = {\n",
    "                'C': [1, 10],\n",
    "                'gamma': ['scale'],\n",
    "                'kernel': ['rbf', 'linear']\n",
    "            }\n",
    "        else:\n",
    "            param_grid = {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'gamma': ['scale'],\n",
    "                'kernel': ['rbf', 'linear', 'poly']\n",
    "            }\n",
    "        \n",
    "        cv_folds = 3 if quick_search else 5\n",
    "        cv_strategy = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=4)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        grid_search = GridSearchCV(\n",
    "            SVC(random_state=4, probability=True), param_grid, cv=cv_strategy, \n",
    "            scoring='accuracy', n_jobs=-1, verbose=0, return_train_score=True\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_tr, y_tr)\n",
    "        search_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"SVM grid search completed in {search_time:.1f} seconds\")\n",
    "        print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        \n",
    "        svm = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_cv_score = grid_search.best_score_\n",
    "    else:\n",
    "        print(f\"Using default SVM parameters...\")\n",
    "        svm = SVC(random_state=4, probability=True)\n",
    "        svm.fit(X_tr, y_tr)\n",
    "        best_params = None\n",
    "        best_cv_score = None\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = svm.predict(X_te)\n",
    "    val_acc = accuracy_score(y_te, y_pred)\n",
    "    print(f\"\\n{len(config['classes_to_use'])}-class SVM test accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_te, y_pred, labels=config[\"classes_to_use\"])\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    target_names = [CLASS_NAMES.get(cls, f\"Class_{cls}\") for cls in config[\"classes_to_use\"]]\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_te, y_pred, labels=config[\"classes_to_use\"], \n",
    "                            target_names=target_names, digits=3))\n",
    "\n",
    "    # Continue with counterfactual evaluation...\n",
    "    print(\"\\nLoading and evaluating counterfactuals...\")\n",
    "    experiments = [\n",
    "        (\"Glacier\", \"Glacier/learning-time-series-counterfactuals\", \"local\", \"cnn\"),\n",
    "        (\"Glacier\", \"Glacier/learning-time-series-counterfactuals\", \"global\", \"cnn\"),\n",
    "        (\"Glacier\", \"Glacier/learning-time-series-counterfactuals\", \"local\", \"ne\"),\n",
    "        (\"Glacier\", \"Glacier/learning-time-series-counterfactuals\", \"global\", \"ne\"),\n",
    "        (\"CELS\", \"CELS/CELS\", \"local\", \"cels\"),\n",
    "        (\"CELS\", \"CELS/CELS\", \"global\", \"cels\"),\n",
    "        (\"RSF\", \"RSF/RSF\", \"local\", \"rsf\"),\n",
    "        (\"RSF\", \"RSF/RSF\", \"global\", \"rsf\"),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    method_stats = defaultdict(lambda: {\"total\": 0, \"strict_success\": 0, \"any_flip\": 0, \n",
    "                                       \"Baseline_Correct\": 0, \"invalid_cf\": 0,\n",
    "                                       \"validated_correct\": 0, \"validated_strict_success\": 0})\n",
    "    \n",
    "    for project_name, project_path, mode, method in experiments:\n",
    "        full_name = f\"{project_name}_{mode}_{method}\"\n",
    "        print(f\"- Evaluating '{full_name}'\")\n",
    "        \n",
    "        # Load counterfactuals\n",
    "        try:\n",
    "            if project_name == \"Glacier\":\n",
    "                result = _load_glacier_concat(project_path, dataset_name, mode, method)\n",
    "            elif project_name == \"CELS\":\n",
    "                result = _load_cels_concat(project_path, dataset_name, mode)\n",
    "            elif project_name == \"RSF\":\n",
    "                result = _load_rsf_concat(project_path, dataset_name, mode)\n",
    "            else:\n",
    "                print(f\"  WARNING: Unknown project name '{project_name}', skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Check if loading was successful\n",
    "            if result is None or all(x is None for x in result):\n",
    "                print(f\"  Skipping '{full_name}': no CF files found.\")\n",
    "                continue\n",
    "                \n",
    "            x_orig, x_cf, y_true, y_pred, y_cf = result\n",
    "            \n",
    "            if x_orig is None:\n",
    "                print(f\"  Skipping '{full_name}': no valid data loaded.\")\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR loading '{full_name}': {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Loaded {len(x_orig)} samples (after concat)\")\n",
    "\n",
    "        \n",
    "        # Apply same preprocessing to CFs if needed\n",
    "        should_preprocess_cfs = use_ramanspy_preprocessing and \"ramanspy\" not in dataset_name.lower()\n",
    "        \n",
    "        if should_preprocess_cfs:\n",
    "            print(f\"  Applying ramanspy preprocessing to CFs from {full_name}\")\n",
    "            try:\n",
    "                orig_spectra = ramanspy.Spectrum(x_orig, np.arange(x_orig.shape[1]))\n",
    "                cf_spectra = ramanspy.Spectrum(x_cf, np.arange(x_cf.shape[1]))\n",
    "                \n",
    "                x_orig = pipeline.apply(orig_spectra).spectral_data\n",
    "                x_cf = pipeline.apply(cf_spectra).spectral_data\n",
    "            except Exception as e:\n",
    "                print(f\"  WARNING: CF preprocessing failed: {e}\")\n",
    "        elif \"ramanspy\" in dataset_name.lower():\n",
    "            print(f\"  Skipping CF preprocessing - {dataset_name} CFs already preprocessed\")\n",
    "\n",
    "        svm_before = svm.predict(x_orig)\n",
    "        svm_after = svm.predict(x_cf)\n",
    "        \n",
    "        stats = method_stats[full_name]\n",
    "        \n",
    "        for i in range(len(x_cf)):\n",
    "            y_bin_orig = int(y_pred[i]) if np.isscalar(y_pred[i]) else int(y_pred[i][0])\n",
    "            y_bin_cf = int(y_cf[i]) if np.isscalar(y_cf[i]) else int(y_cf[i][0])\n",
    "\n",
    "                \n",
    "                \n",
    "            orig_family = BIN2ORIG[y_bin_orig]\n",
    "            target_family = BIN2ORIG[y_bin_cf]\n",
    "\n",
    "            svm_before_lbl = int(svm_before[i])\n",
    "            svm_after_lbl = int(svm_after[i])\n",
    "\n",
    "            # did classifier place the original in its own family?\n",
    "            svm_before_ok = (svm_before_lbl in orig_family)\n",
    "            \n",
    "            # Did the ground truth match the original family?\n",
    "            y_true_lbl = int(y_true[i]) if np.isscalar(y_true[i]) else int(y_true[i][0])\n",
    "            ground_truth_ok = (y_true_lbl == y_bin_orig)\n",
    "\n",
    "            # Any Flip\n",
    "            any_ok = (svm_after_lbl not in orig_family)\n",
    "\n",
    "            # Strict Flip. landed specifically in the intended target family\n",
    "            strict_ok = any_ok and (svm_after_lbl in target_family)\n",
    "\n",
    "            # was the CF different\n",
    "            cf_different = not np.allclose(x_orig[i], x_cf[i], rtol=1e-3)\n",
    "\n",
    "            # meaningful CF metric\n",
    "            meaningful_cf = (svm_before_lbl in orig_family) and (svm_after_lbl not in orig_family)\n",
    "            \n",
    "            # Both ground truth AND SVM agree original was correct\n",
    "            validated_correct = ground_truth_ok and svm_before_ok\n",
    "            \n",
    "            # Strict success from a validated correct original\n",
    "            validated_strict_success = validated_correct and strict_ok\n",
    "\n",
    "            # Distance metrics\n",
    "            dist_abs = float(np.linalg.norm(x_orig[i] - x_cf[i]))\n",
    "            denom = max(1e-8, np.linalg.norm(x_orig[i]))\n",
    "            dist_rel = float(dist_abs / denom)\n",
    "\n",
    "            stats[\"total\"] += 1\n",
    "            if svm_before_ok: stats[\"Baseline_Correct\"] += 1\n",
    "            if strict_ok: stats[\"strict_success\"] += 1\n",
    "            if any_ok: stats[\"any_flip\"] += 1\n",
    "            if not cf_different: stats[\"invalid_cf\"] += 1\n",
    "            if validated_correct: stats[\"validated_correct\"] += 1\n",
    "            if validated_strict_success: stats[\"validated_strict_success\"] += 1\n",
    "\n",
    "            results.append({\n",
    "                \"Method\": full_name,\n",
    "                \"svm_before\": svm_before_lbl,\n",
    "                \"svm_after\": svm_after_lbl,\n",
    "\n",
    "                \"success_strict\": strict_ok,\n",
    "                \"flipped_any\": any_ok,\n",
    "\n",
    "                \"Baseline_Correct\": svm_before_ok,\n",
    "                \"cf_different\": cf_different,\n",
    "                \"meaningful_cf\": meaningful_cf,\n",
    "                \n",
    "                \"validated_correct\": validated_correct,\n",
    "                \"validated_strict_success\": validated_strict_success,\n",
    "\n",
    "                \"distance\": dist_abs,\n",
    "                \"rel_distance\": dist_rel,\n",
    "\n",
    "                \"y_bin_orig\": y_bin_orig,\n",
    "                \"y_bin_cf\": y_bin_cf,\n",
    "                \"orig_class_name\": CLASS_NAMES.get(svm_before_lbl, f\"Class_{svm_before_lbl}\"),\n",
    "                \"cf_class_name\": CLASS_NAMES.get(svm_after_lbl, f\"Class_{svm_after_lbl}\"),\n",
    "            })\n",
    "\n",
    "    if not results:\n",
    "        print(\"No valid results found!\")\n",
    "        return None\n",
    "\n",
    "    df_all = pd.DataFrame(results)\n",
    "    df_all[\"strict_given_baseline\"] = df_all[\"success_strict\"] & df_all[\"Baseline_Correct\"]\n",
    "\n",
    "    # Create summary table with new metrics\n",
    "    agg = df_all.groupby(\"Method\").agg(\n",
    "        N=(\"success_strict\", \"size\"),\n",
    "        Total_Any_Flips=(\"flipped_any\", \"sum\"),\n",
    "        Total_Strict_Flips_from_Correct=(\"strict_given_baseline\", \"sum\"),\n",
    "        Total_Validated_Correct=(\"validated_correct\", \"sum\"),\n",
    "        Total_Validated_Strict_Success=(\"validated_strict_success\", \"sum\"),\n",
    "        Avg_Distance=(\"distance\", \"mean\"),\n",
    "        Avg_Rel_Proximity=(\"rel_distance\", \"mean\"),\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate the three key metrics\n",
    "    # 1. AFR: Any Flip Rate = Total Any Flips / Total CFs Generated\n",
    "    agg[\"AFR\"] = agg[\"Total_Any_Flips\"] / agg[\"N\"]\n",
    "    \n",
    "    # 2. MSR: Meaningful Success Rate = Strict Flips from Correct / Total CFs Generated\n",
    "    agg[\"MSR\"] = agg[\"Total_Strict_Flips_from_Correct\"] / agg[\"N\"]\n",
    "    \n",
    "    # 3. CSR: Conditional Success Rate\n",
    "    #    Only counts cases where BOTH ground truth AND SVM agree original was correct\n",
    "    agg[\"CSR\"] = agg[\"Total_Validated_Strict_Success\"] / agg[\"Total_Validated_Correct\"]\n",
    "    \n",
    "    # Reorder columns for better presentation\n",
    "    agg = agg[[\"Method\", \"N\", \"AFR\", \"MSR\", \"CSR\", \n",
    "               \"Total_Validated_Correct\",\n",
    "               \"Avg_Distance\", \"Avg_Rel_Proximity\"]]\n",
    "\n",
    "    pretty = agg.copy()\n",
    "    pct_cols = [\"AFR\", \"MSR\", \"CSR\"]\n",
    "    for c in pct_cols:\n",
    "        pretty[c] = (pretty[c] * 100).round(1).astype(str) + \"%\"\n",
    "\n",
    "    pretty[\"Avg_Distance\"] = pretty[\"Avg_Distance\"].round(3)\n",
    "    pretty[\"Avg_Rel_Proximity\"] = pretty[\"Avg_Rel_Proximity\"].round(3)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SVM EVALUATION RESULTS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nMetric Definitions:\")\n",
    "    print(\"  AFR (Any Flip Rate): % of CFs that changed prediction to ANY other class\")\n",
    "    print(\"  MSR (Meaningful Success Rate): % of CFs with correct original -> correct target flip\")\n",
    "    print(\"  CSR (Conditional Success Rate): Success rate GIVEN ground truth AND SVM agree original was correct\")\n",
    "    print(\"=\"*80)\n",
    "    display(pretty.style.hide(axis='index'))\n",
    "\n",
    "    result_dict = {\n",
    "        'results_df': df_all,\n",
    "        'summary_df': agg,\n",
    "        'best_svm_model': svm,\n",
    "    }\n",
    "    \n",
    "    if perform_gridsearch:\n",
    "        result_dict['svm_best_params'] = best_params\n",
    "        result_dict['svm_best_cv_score'] = best_cv_score\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b105e89",
   "metadata": {},
   "source": [
    "### Run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8824edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quick_evaluation(dataset_name, use_ramanspy_preprocessing=False):\n",
    "    \"\"\"Quick evaluation with limited hyperparameter search\"\"\"\n",
    "    return run_multiclass_evaluation(\n",
    "        dataset_name, \n",
    "        use_ramanspy_preprocessing,\n",
    "        perform_gridsearch=True, \n",
    "        quick_search=True\n",
    "    )\n",
    "def run_comprehensive_evaluation(dataset_name, use_ramanspy_preprocessing=False):\n",
    "    \"\"\"Comprehensive evaluation with full hyperparameter search\"\"\"\n",
    "    return run_multiclass_evaluation(\n",
    "        dataset_name, \n",
    "        use_ramanspy_preprocessing,\n",
    "        perform_gridsearch=True, \n",
    "        quick_search=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e5d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Running Multi-Class Evaluation for: DRS_TissueClassification\n",
      "Hyperparameter Tuning: GridSearchCV enabled\n",
      "============================================================\n",
      "Loading reference spectra...\n",
      "DRS tissue distribution: {np.int64(0): np.int64(1000), np.int64(1): np.int64(1000), np.int64(2): np.int64(1000), np.int64(3): np.int64(1000), np.int64(4): np.int64(1000), np.int64(5): np.int64(215)}\n",
      "Loaded reference data: X_all.shape=(5215, 1531), y_all.shape=(5215,)\n",
      "Unique classes in reference: [0 1 2 3 4 5]\n",
      "After filtering to relevant classes: X_sub.shape=(5215, 1531)\n",
      "Class distribution: {np.int64(0): np.int64(1000), np.int64(1): np.int64(1000), np.int64(2): np.int64(1000), np.int64(3): np.int64(1000), np.int64(4): np.int64(1000), np.int64(5): np.int64(215)}\n",
      "\n",
      "--- Training SVM ---\n",
      "Performing hyperparameter tuning for SVM...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "SVM grid search completed in 225.0 seconds\n",
      "Best CV score: 0.9871\n",
      "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "6-class SVM test accuracy: 0.9895\n",
      "Confusion Matrix:\n",
      "[[200   0   0   0   0   0]\n",
      " [  1 199   0   0   0   0]\n",
      " [  0   0 195   2   3   0]\n",
      " [  0   1   0 199   0   0]\n",
      " [  0   0   4   0 196   0]\n",
      " [  0   0   0   0   0  43]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      muscle      0.995     1.000     0.998       200\n",
      "    cortBone      0.995     0.995     0.995       200\n",
      "     traBone      0.980     0.975     0.977       200\n",
      "   cartilage      0.990     0.995     0.993       200\n",
      "  boneMarrow      0.985     0.980     0.982       200\n",
      "  boneCement      1.000     1.000     1.000        43\n",
      "\n",
      "    accuracy                          0.989      1043\n",
      "   macro avg      0.991     0.991     0.991      1043\n",
      "weighted avg      0.989     0.989     0.989      1043\n",
      "\n",
      "\n",
      "Loading and evaluating counterfactuals...\n",
      "- Evaluating 'Glacier_local_cnn'\n",
      "  [Glacier] loaded cf_fold1_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold2_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold3_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold4_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold5_cnn.npz: 100 samples\n",
      "  [Glacier] concatenated local/cnn: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "- Evaluating 'Glacier_global_cnn'\n",
      "  [Glacier] loaded cf_fold1_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold2_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold3_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold4_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold5_cnn.npz: 100 samples\n",
      "  [Glacier] concatenated global/cnn: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "- Evaluating 'Glacier_local_ne'\n",
      "  [Glacier] loaded cf_fold1_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold2_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold3_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold4_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold5_ne.npz: 100 samples\n",
      "  [Glacier] concatenated local/ne: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "- Evaluating 'Glacier_global_ne'\n",
      "  [Glacier] loaded cf_fold1_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold2_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold3_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold4_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold5_ne.npz: 100 samples\n",
      "  [Glacier] concatenated global/ne: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "- Evaluating 'CELS_local_cels'\n",
      "  [CELS] loaded cf_fold0.npz: 100 samples\n",
      "  [CELS] loaded cf_fold1.npz: 100 samples\n",
      "  [CELS] loaded cf_fold2.npz: 100 samples\n",
      "  [CELS] loaded cf_fold3.npz: 100 samples\n",
      "  [CELS] loaded cf_fold4.npz: 100 samples\n",
      "  [CELS] concatenated local: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "- Evaluating 'CELS_global_cels'\n",
      "  [CELS] loaded cf_fold0.npz: 100 samples\n",
      "  [CELS] loaded cf_fold1.npz: 100 samples\n",
      "  [CELS] loaded cf_fold2.npz: 100 samples\n",
      "  [CELS] loaded cf_fold3.npz: 100 samples\n",
      "  [CELS] loaded cf_fold4.npz: 100 samples\n",
      "  [CELS] concatenated global: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "- Evaluating 'RSF_local_rsf'\n",
      "  [RSF] loaded cf_fold0.npz: 100 samples\n",
      "  [RSF] loaded cf_fold1.npz: 100 samples\n",
      "  [RSF] loaded cf_fold2.npz: 100 samples\n",
      "  [RSF] loaded cf_fold3.npz: 100 samples\n",
      "  [RSF] loaded cf_fold4.npz: 100 samples\n",
      "  [RSF] concatenated local: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "- Evaluating 'RSF_global_rsf'\n",
      "  [RSF] loaded cf_fold0.npz: 100 samples\n",
      "  [RSF] loaded cf_fold1.npz: 100 samples\n",
      "  [RSF] loaded cf_fold2.npz: 100 samples\n",
      "  [RSF] loaded cf_fold3.npz: 100 samples\n",
      "  [RSF] loaded cf_fold4.npz: 100 samples\n",
      "  [RSF] concatenated global: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "\n",
      "================================================================================\n",
      "SVM EVALUATION RESULTS:\n",
      "================================================================================\n",
      "\n",
      "Metric Definitions:\n",
      "  AFR (Any Flip Rate): % of CFs that changed prediction to ANY other class\n",
      "  MSR (Meaningful Success Rate): % of CFs with correct original -> correct target flip\n",
      "  CSR (Conditional Success Rate): Success rate GIVEN ground truth AND SVM agree original was correct\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_74b3a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_74b3a_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_74b3a_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_74b3a_level0_col2\" class=\"col_heading level0 col2\" >AFR</th>\n",
       "      <th id=\"T_74b3a_level0_col3\" class=\"col_heading level0 col3\" >MSR</th>\n",
       "      <th id=\"T_74b3a_level0_col4\" class=\"col_heading level0 col4\" >CSR</th>\n",
       "      <th id=\"T_74b3a_level0_col5\" class=\"col_heading level0 col5\" >Total_Validated_Correct</th>\n",
       "      <th id=\"T_74b3a_level0_col6\" class=\"col_heading level0 col6\" >Avg_Distance</th>\n",
       "      <th id=\"T_74b3a_level0_col7\" class=\"col_heading level0 col7\" >Avg_Rel_Proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_74b3a_row0_col0\" class=\"data row0 col0\" >CELS_global_cels</td>\n",
       "      <td id=\"T_74b3a_row0_col1\" class=\"data row0 col1\" >500</td>\n",
       "      <td id=\"T_74b3a_row0_col2\" class=\"data row0 col2\" >0.4%</td>\n",
       "      <td id=\"T_74b3a_row0_col3\" class=\"data row0 col3\" >0.0%</td>\n",
       "      <td id=\"T_74b3a_row0_col4\" class=\"data row0 col4\" >0.0%</td>\n",
       "      <td id=\"T_74b3a_row0_col5\" class=\"data row0 col5\" >497</td>\n",
       "      <td id=\"T_74b3a_row0_col6\" class=\"data row0 col6\" >1.864000</td>\n",
       "      <td id=\"T_74b3a_row0_col7\" class=\"data row0 col7\" >0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_74b3a_row1_col0\" class=\"data row1 col0\" >CELS_local_cels</td>\n",
       "      <td id=\"T_74b3a_row1_col1\" class=\"data row1 col1\" >500</td>\n",
       "      <td id=\"T_74b3a_row1_col2\" class=\"data row1 col2\" >1.6%</td>\n",
       "      <td id=\"T_74b3a_row1_col3\" class=\"data row1 col3\" >0.0%</td>\n",
       "      <td id=\"T_74b3a_row1_col4\" class=\"data row1 col4\" >0.0%</td>\n",
       "      <td id=\"T_74b3a_row1_col5\" class=\"data row1 col5\" >497</td>\n",
       "      <td id=\"T_74b3a_row1_col6\" class=\"data row1 col6\" >0.797000</td>\n",
       "      <td id=\"T_74b3a_row1_col7\" class=\"data row1 col7\" >0.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_74b3a_row2_col0\" class=\"data row2 col0\" >Glacier_global_cnn</td>\n",
       "      <td id=\"T_74b3a_row2_col1\" class=\"data row2 col1\" >500</td>\n",
       "      <td id=\"T_74b3a_row2_col2\" class=\"data row2 col2\" >36.4%</td>\n",
       "      <td id=\"T_74b3a_row2_col3\" class=\"data row2 col3\" >23.0%</td>\n",
       "      <td id=\"T_74b3a_row2_col4\" class=\"data row2 col4\" >23.3%</td>\n",
       "      <td id=\"T_74b3a_row2_col5\" class=\"data row2 col5\" >493</td>\n",
       "      <td id=\"T_74b3a_row2_col6\" class=\"data row2 col6\" >1.246000</td>\n",
       "      <td id=\"T_74b3a_row2_col7\" class=\"data row2 col7\" >0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_74b3a_row3_col0\" class=\"data row3 col0\" >Glacier_global_ne</td>\n",
       "      <td id=\"T_74b3a_row3_col1\" class=\"data row3 col1\" >500</td>\n",
       "      <td id=\"T_74b3a_row3_col2\" class=\"data row3 col2\" >6.0%</td>\n",
       "      <td id=\"T_74b3a_row3_col3\" class=\"data row3 col3\" >3.0%</td>\n",
       "      <td id=\"T_74b3a_row3_col4\" class=\"data row3 col4\" >3.0%</td>\n",
       "      <td id=\"T_74b3a_row3_col5\" class=\"data row3 col5\" >493</td>\n",
       "      <td id=\"T_74b3a_row3_col6\" class=\"data row3 col6\" >1.067000</td>\n",
       "      <td id=\"T_74b3a_row3_col7\" class=\"data row3 col7\" >0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_74b3a_row4_col0\" class=\"data row4 col0\" >Glacier_local_cnn</td>\n",
       "      <td id=\"T_74b3a_row4_col1\" class=\"data row4 col1\" >500</td>\n",
       "      <td id=\"T_74b3a_row4_col2\" class=\"data row4 col2\" >23.8%</td>\n",
       "      <td id=\"T_74b3a_row4_col3\" class=\"data row4 col3\" >15.8%</td>\n",
       "      <td id=\"T_74b3a_row4_col4\" class=\"data row4 col4\" >16.0%</td>\n",
       "      <td id=\"T_74b3a_row4_col5\" class=\"data row4 col5\" >493</td>\n",
       "      <td id=\"T_74b3a_row4_col6\" class=\"data row4 col6\" >1.392000</td>\n",
       "      <td id=\"T_74b3a_row4_col7\" class=\"data row4 col7\" >0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_74b3a_row5_col0\" class=\"data row5 col0\" >Glacier_local_ne</td>\n",
       "      <td id=\"T_74b3a_row5_col1\" class=\"data row5 col1\" >500</td>\n",
       "      <td id=\"T_74b3a_row5_col2\" class=\"data row5 col2\" >2.8%</td>\n",
       "      <td id=\"T_74b3a_row5_col3\" class=\"data row5 col3\" >0.8%</td>\n",
       "      <td id=\"T_74b3a_row5_col4\" class=\"data row5 col4\" >0.8%</td>\n",
       "      <td id=\"T_74b3a_row5_col5\" class=\"data row5 col5\" >493</td>\n",
       "      <td id=\"T_74b3a_row5_col6\" class=\"data row5 col6\" >1.020000</td>\n",
       "      <td id=\"T_74b3a_row5_col7\" class=\"data row5 col7\" >0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_74b3a_row6_col0\" class=\"data row6 col0\" >RSF_global_rsf</td>\n",
       "      <td id=\"T_74b3a_row6_col1\" class=\"data row6 col1\" >500</td>\n",
       "      <td id=\"T_74b3a_row6_col2\" class=\"data row6 col2\" >65.0%</td>\n",
       "      <td id=\"T_74b3a_row6_col3\" class=\"data row6 col3\" >35.2%</td>\n",
       "      <td id=\"T_74b3a_row6_col4\" class=\"data row6 col4\" >35.8%</td>\n",
       "      <td id=\"T_74b3a_row6_col5\" class=\"data row6 col5\" >491</td>\n",
       "      <td id=\"T_74b3a_row6_col6\" class=\"data row6 col6\" >3.436000</td>\n",
       "      <td id=\"T_74b3a_row6_col7\" class=\"data row6 col7\" >0.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_74b3a_row7_col0\" class=\"data row7 col0\" >RSF_local_rsf</td>\n",
       "      <td id=\"T_74b3a_row7_col1\" class=\"data row7 col1\" >500</td>\n",
       "      <td id=\"T_74b3a_row7_col2\" class=\"data row7 col2\" >36.8%</td>\n",
       "      <td id=\"T_74b3a_row7_col3\" class=\"data row7 col3\" >25.2%</td>\n",
       "      <td id=\"T_74b3a_row7_col4\" class=\"data row7 col4\" >25.7%</td>\n",
       "      <td id=\"T_74b3a_row7_col5\" class=\"data row7 col5\" >491</td>\n",
       "      <td id=\"T_74b3a_row7_col6\" class=\"data row7 col6\" >2.061000</td>\n",
       "      <td id=\"T_74b3a_row7_col7\" class=\"data row7 col7\" >0.083000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f068e5f2250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TissueMetrics = run_comprehensive_evaluation(\n",
    "    \"DRS_TissueClassification\", \n",
    "    use_ramanspy_preprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc88dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Running Multi-Class Evaluation for: RamanCOVID19_ramanspy_preprocessed\n",
      "Preprocessing Mode: ramanspy\n",
      "Hyperparameter Tuning: GridSearchCV enabled\n",
      "============================================================\n",
      "Loading reference spectra...\n",
      "Loaded reference data: X_all.shape=(465, 900), y_all.shape=(465,)\n",
      "Unique classes in reference: [0 1 2]\n",
      "Applying ramanspy preprocessing to reference data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed successfully\n",
      "After filtering to relevant classes: X_sub.shape=(465, 900)\n",
      "Class distribution: {np.int64(0): np.int64(150), np.int64(1): np.int64(159), np.int64(2): np.int64(156)}\n",
      "\n",
      "--- Training SVM ---\n",
      "Performing hyperparameter tuning for SVM...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "SVM grid search completed in 0.9 seconds\n",
      "Best CV score: 0.8039\n",
      "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "3-class SVM test accuracy: 0.8280\n",
      "Confusion Matrix:\n",
      "[[26  0  4]\n",
      " [ 2 29  1]\n",
      " [ 8  1 22]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy      0.722     0.867     0.788        30\n",
      "    COVID-19      0.967     0.906     0.935        32\n",
      "   Suspected      0.815     0.710     0.759        31\n",
      "\n",
      "    accuracy                          0.828        93\n",
      "   macro avg      0.835     0.828     0.827        93\n",
      "weighted avg      0.837     0.828     0.829        93\n",
      "\n",
      "\n",
      "Loading and evaluating counterfactuals...\n",
      "- Evaluating 'Glacier_local_cnn'\n",
      "  [Glacier] loaded cf_fold1_cnn.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold2_cnn.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold3_cnn.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold4_cnn.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold5_cnn.npz: 61 samples\n",
      "  [Glacier] concatenated local/cnn: 309 samples total\n",
      "  Loaded 309 samples (after concat)\n",
      "  Skipping CF preprocessing - RamanCOVID19_ramanspy_preprocessed CFs already preprocessed\n",
      "- Evaluating 'Glacier_global_cnn'\n",
      "  [Glacier] loaded cf_fold1_cnn.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold2_cnn.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold3_cnn.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold4_cnn.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold5_cnn.npz: 61 samples\n",
      "  [Glacier] concatenated global/cnn: 309 samples total\n",
      "  Loaded 309 samples (after concat)\n",
      "  Skipping CF preprocessing - RamanCOVID19_ramanspy_preprocessed CFs already preprocessed\n",
      "- Evaluating 'Glacier_local_ne'\n",
      "  [Glacier] loaded cf_fold1_ne.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold2_ne.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold3_ne.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold4_ne.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold5_ne.npz: 61 samples\n",
      "  [Glacier] concatenated local/ne: 309 samples total\n",
      "  Loaded 309 samples (after concat)\n",
      "  Skipping CF preprocessing - RamanCOVID19_ramanspy_preprocessed CFs already preprocessed\n",
      "- Evaluating 'Glacier_global_ne'\n",
      "  [Glacier] loaded cf_fold1_ne.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold2_ne.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold3_ne.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold4_ne.npz: 62 samples\n",
      "  [Glacier] loaded cf_fold5_ne.npz: 61 samples\n",
      "  [Glacier] concatenated global/ne: 309 samples total\n",
      "  Loaded 309 samples (after concat)\n",
      "  Skipping CF preprocessing - RamanCOVID19_ramanspy_preprocessed CFs already preprocessed\n",
      "- Evaluating 'CELS_local_cels'\n",
      "  [CELS] loaded cf_fold0.npz: 62 samples\n",
      "  [CELS] loaded cf_fold1.npz: 62 samples\n",
      "  [CELS] loaded cf_fold2.npz: 62 samples\n",
      "  [CELS] loaded cf_fold3.npz: 62 samples\n",
      "  [CELS] loaded cf_fold4.npz: 61 samples\n",
      "  [CELS] concatenated local: 309 samples total\n",
      "  Loaded 309 samples (after concat)\n",
      "  Skipping CF preprocessing - RamanCOVID19_ramanspy_preprocessed CFs already preprocessed\n",
      "- Evaluating 'CELS_global_cels'\n",
      "  [CELS] loaded cf_fold0.npz: 62 samples\n",
      "  [CELS] loaded cf_fold1.npz: 62 samples\n",
      "  [CELS] loaded cf_fold2.npz: 62 samples\n",
      "  [CELS] loaded cf_fold3.npz: 62 samples\n",
      "  [CELS] loaded cf_fold4.npz: 61 samples\n",
      "  [CELS] concatenated global: 309 samples total\n",
      "  Loaded 309 samples (after concat)\n",
      "  Skipping CF preprocessing - RamanCOVID19_ramanspy_preprocessed CFs already preprocessed\n",
      "- Evaluating 'RSF_local_rsf'\n",
      "  [RSF] loaded cf_fold0.npz: 62 samples\n",
      "  [RSF] loaded cf_fold1.npz: 62 samples\n",
      "  [RSF] loaded cf_fold2.npz: 62 samples\n",
      "  [RSF] loaded cf_fold3.npz: 62 samples\n",
      "  [RSF] loaded cf_fold4.npz: 61 samples\n",
      "  [RSF] concatenated local: 309 samples total\n",
      "  Loaded 309 samples (after concat)\n",
      "  Skipping CF preprocessing - RamanCOVID19_ramanspy_preprocessed CFs already preprocessed\n",
      "- Evaluating 'RSF_global_rsf'\n",
      "  [RSF] loaded cf_fold0.npz: 62 samples\n",
      "  [RSF] loaded cf_fold1.npz: 62 samples\n",
      "  [RSF] loaded cf_fold2.npz: 62 samples\n",
      "  [RSF] loaded cf_fold3.npz: 62 samples\n",
      "  [RSF] loaded cf_fold4.npz: 61 samples\n",
      "  [RSF] concatenated global: 309 samples total\n",
      "  Loaded 309 samples (after concat)\n",
      "  Skipping CF preprocessing - RamanCOVID19_ramanspy_preprocessed CFs already preprocessed\n",
      "\n",
      "================================================================================\n",
      "SVM EVALUATION RESULTS:\n",
      "================================================================================\n",
      "\n",
      "Metric Definitions:\n",
      "  AFR (Any Flip Rate): % of CFs that changed prediction to ANY other class\n",
      "  MSR (Meaningful Success Rate): % of CFs with correct original -> correct target flip\n",
      "  CSR (Conditional Success Rate): Success rate GIVEN ground truth AND SVM agree original was correct\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_dc2a9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_dc2a9_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_dc2a9_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_dc2a9_level0_col2\" class=\"col_heading level0 col2\" >AFR</th>\n",
       "      <th id=\"T_dc2a9_level0_col3\" class=\"col_heading level0 col3\" >MSR</th>\n",
       "      <th id=\"T_dc2a9_level0_col4\" class=\"col_heading level0 col4\" >CSR</th>\n",
       "      <th id=\"T_dc2a9_level0_col5\" class=\"col_heading level0 col5\" >Total_Validated_Correct</th>\n",
       "      <th id=\"T_dc2a9_level0_col6\" class=\"col_heading level0 col6\" >Avg_Distance</th>\n",
       "      <th id=\"T_dc2a9_level0_col7\" class=\"col_heading level0 col7\" >Avg_Rel_Proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_dc2a9_row0_col0\" class=\"data row0 col0\" >CELS_global_cels</td>\n",
       "      <td id=\"T_dc2a9_row0_col1\" class=\"data row0 col1\" >309</td>\n",
       "      <td id=\"T_dc2a9_row0_col2\" class=\"data row0 col2\" >69.3%</td>\n",
       "      <td id=\"T_dc2a9_row0_col3\" class=\"data row0 col3\" >2.3%</td>\n",
       "      <td id=\"T_dc2a9_row0_col4\" class=\"data row0 col4\" >4.7%</td>\n",
       "      <td id=\"T_dc2a9_row0_col5\" class=\"data row0 col5\" >148</td>\n",
       "      <td id=\"T_dc2a9_row0_col6\" class=\"data row0 col6\" >0.510000</td>\n",
       "      <td id=\"T_dc2a9_row0_col7\" class=\"data row0 col7\" >0.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc2a9_row1_col0\" class=\"data row1 col0\" >CELS_local_cels</td>\n",
       "      <td id=\"T_dc2a9_row1_col1\" class=\"data row1 col1\" >309</td>\n",
       "      <td id=\"T_dc2a9_row1_col2\" class=\"data row1 col2\" >80.9%</td>\n",
       "      <td id=\"T_dc2a9_row1_col3\" class=\"data row1 col3\" >9.1%</td>\n",
       "      <td id=\"T_dc2a9_row1_col4\" class=\"data row1 col4\" >18.9%</td>\n",
       "      <td id=\"T_dc2a9_row1_col5\" class=\"data row1 col5\" >148</td>\n",
       "      <td id=\"T_dc2a9_row1_col6\" class=\"data row1 col6\" >0.281000</td>\n",
       "      <td id=\"T_dc2a9_row1_col7\" class=\"data row1 col7\" >0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc2a9_row2_col0\" class=\"data row2 col0\" >Glacier_global_cnn</td>\n",
       "      <td id=\"T_dc2a9_row2_col1\" class=\"data row2 col1\" >309</td>\n",
       "      <td id=\"T_dc2a9_row2_col2\" class=\"data row2 col2\" >90.3%</td>\n",
       "      <td id=\"T_dc2a9_row2_col3\" class=\"data row2 col3\" >8.7%</td>\n",
       "      <td id=\"T_dc2a9_row2_col4\" class=\"data row2 col4\" >47.1%</td>\n",
       "      <td id=\"T_dc2a9_row2_col5\" class=\"data row2 col5\" >51</td>\n",
       "      <td id=\"T_dc2a9_row2_col6\" class=\"data row2 col6\" >2.079000</td>\n",
       "      <td id=\"T_dc2a9_row2_col7\" class=\"data row2 col7\" >0.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc2a9_row3_col0\" class=\"data row3 col0\" >Glacier_global_ne</td>\n",
       "      <td id=\"T_dc2a9_row3_col1\" class=\"data row3 col1\" >309</td>\n",
       "      <td id=\"T_dc2a9_row3_col2\" class=\"data row3 col2\" >68.0%</td>\n",
       "      <td id=\"T_dc2a9_row3_col3\" class=\"data row3 col3\" >2.6%</td>\n",
       "      <td id=\"T_dc2a9_row3_col4\" class=\"data row3 col4\" >9.8%</td>\n",
       "      <td id=\"T_dc2a9_row3_col5\" class=\"data row3 col5\" >51</td>\n",
       "      <td id=\"T_dc2a9_row3_col6\" class=\"data row3 col6\" >1.080000</td>\n",
       "      <td id=\"T_dc2a9_row3_col7\" class=\"data row3 col7\" >0.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc2a9_row4_col0\" class=\"data row4 col0\" >Glacier_local_cnn</td>\n",
       "      <td id=\"T_dc2a9_row4_col1\" class=\"data row4 col1\" >309</td>\n",
       "      <td id=\"T_dc2a9_row4_col2\" class=\"data row4 col2\" >56.3%</td>\n",
       "      <td id=\"T_dc2a9_row4_col3\" class=\"data row4 col3\" >2.6%</td>\n",
       "      <td id=\"T_dc2a9_row4_col4\" class=\"data row4 col4\" >13.7%</td>\n",
       "      <td id=\"T_dc2a9_row4_col5\" class=\"data row4 col5\" >51</td>\n",
       "      <td id=\"T_dc2a9_row4_col6\" class=\"data row4 col6\" >2.299000</td>\n",
       "      <td id=\"T_dc2a9_row4_col7\" class=\"data row4 col7\" >0.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc2a9_row5_col0\" class=\"data row5 col0\" >Glacier_local_ne</td>\n",
       "      <td id=\"T_dc2a9_row5_col1\" class=\"data row5 col1\" >309</td>\n",
       "      <td id=\"T_dc2a9_row5_col2\" class=\"data row5 col2\" >64.1%</td>\n",
       "      <td id=\"T_dc2a9_row5_col3\" class=\"data row5 col3\" >0.6%</td>\n",
       "      <td id=\"T_dc2a9_row5_col4\" class=\"data row5 col4\" >2.0%</td>\n",
       "      <td id=\"T_dc2a9_row5_col5\" class=\"data row5 col5\" >51</td>\n",
       "      <td id=\"T_dc2a9_row5_col6\" class=\"data row5 col6\" >1.025000</td>\n",
       "      <td id=\"T_dc2a9_row5_col7\" class=\"data row5 col7\" >0.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc2a9_row6_col0\" class=\"data row6 col0\" >RSF_global_rsf</td>\n",
       "      <td id=\"T_dc2a9_row6_col1\" class=\"data row6 col1\" >309</td>\n",
       "      <td id=\"T_dc2a9_row6_col2\" class=\"data row6 col2\" >82.2%</td>\n",
       "      <td id=\"T_dc2a9_row6_col3\" class=\"data row6 col3\" >12.0%</td>\n",
       "      <td id=\"T_dc2a9_row6_col4\" class=\"data row6 col4\" >26.1%</td>\n",
       "      <td id=\"T_dc2a9_row6_col5\" class=\"data row6 col5\" >142</td>\n",
       "      <td id=\"T_dc2a9_row6_col6\" class=\"data row6 col6\" >0.567000</td>\n",
       "      <td id=\"T_dc2a9_row6_col7\" class=\"data row6 col7\" >0.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc2a9_row7_col0\" class=\"data row7 col0\" >RSF_local_rsf</td>\n",
       "      <td id=\"T_dc2a9_row7_col1\" class=\"data row7 col1\" >309</td>\n",
       "      <td id=\"T_dc2a9_row7_col2\" class=\"data row7 col2\" >84.5%</td>\n",
       "      <td id=\"T_dc2a9_row7_col3\" class=\"data row7 col3\" >5.8%</td>\n",
       "      <td id=\"T_dc2a9_row7_col4\" class=\"data row7 col4\" >12.7%</td>\n",
       "      <td id=\"T_dc2a9_row7_col5\" class=\"data row7 col5\" >142</td>\n",
       "      <td id=\"T_dc2a9_row7_col6\" class=\"data row7 col6\" >0.647000</td>\n",
       "      <td id=\"T_dc2a9_row7_col7\" class=\"data row7 col7\" >0.111000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0696d581d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CovidMetrics = run_comprehensive_evaluation(\n",
    "    \"RamanCOVID19_ramanspy_preprocessed\", \n",
    "    use_ramanspy_preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826677f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Running Multi-Class Evaluation for: EcoliVsKpneumoniae_ramanspy_singular\n",
      "Preprocessing Mode: ramanspy\n",
      "Hyperparameter Tuning: GridSearchCV enabled\n",
      "============================================================\n",
      "Loading reference spectra...\n",
      "Loaded reference data: X_all.shape=(60000, 1000), y_all.shape=(60000,)\n",
      "Unique classes in reference: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29.]\n",
      "Applying ramanspy preprocessing to reference data...\n",
      "Preprocessing completed successfully\n",
      "After filtering to relevant classes: X_sub.shape=(10000, 1000)\n",
      "Class distribution: {np.float64(0.0): np.int64(2000), np.float64(1.0): np.int64(2000), np.float64(2.0): np.int64(2000), np.float64(3.0): np.int64(2000), np.float64(9.0): np.int64(2000)}\n",
      "\n",
      "--- Training SVM ---\n",
      "Performing hyperparameter tuning for SVM...\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "SVM grid search completed in 407.8 seconds\n",
      "Best CV score: 0.9755\n",
      "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "5-class SVM test accuracy: 0.9760\n",
      "Confusion Matrix:\n",
      "[[399   1   0   0   0]\n",
      " [  1 399   0   0   0]\n",
      " [  0   0 390   9   1]\n",
      " [  0   0  17 379   4]\n",
      " [  0   3   3   9 385]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  C.albicans      0.998     0.998     0.998       400\n",
      "  C.glabrata      0.990     0.998     0.994       400\n",
      " K.aerogenes      0.951     0.975     0.963       400\n",
      "    E.coli_1      0.955     0.948     0.951       400\n",
      "   K.pneum_1      0.987     0.963     0.975       400\n",
      "\n",
      "    accuracy                          0.976      2000\n",
      "   macro avg      0.976     0.976     0.976      2000\n",
      "weighted avg      0.976     0.976     0.976      2000\n",
      "\n",
      "\n",
      "Loading and evaluating counterfactuals...\n",
      "- Evaluating 'Glacier_local_cnn'\n",
      "  [Glacier] loaded cf_fold1_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold2_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold3_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold4_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold5_cnn.npz: 100 samples\n",
      "  [Glacier] concatenated local/cnn: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "  DEBUG: y_pred unique: [0 1]\n",
      "  DEBUG: y_cf unique: [0 1]\n",
      "  DEBUG: y_true unique: [0 1]\n",
      "  DEBUG: First 5 - y_pred: [1 1 0 1 0], y_true: [1 1 0 0 0]\n",
      "  Skipping CF preprocessing - EcoliVsKpneumoniae_ramanspy_singular CFs already preprocessed\n",
      "- Evaluating 'Glacier_global_cnn'\n",
      "  [Glacier] loaded cf_fold1_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold2_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold3_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold4_cnn.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold5_cnn.npz: 100 samples\n",
      "  [Glacier] concatenated global/cnn: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "  DEBUG: y_pred unique: [0 1]\n",
      "  DEBUG: y_cf unique: [0 1]\n",
      "  DEBUG: y_true unique: [0 1]\n",
      "  DEBUG: First 5 - y_pred: [1 1 0 1 0], y_true: [1 1 0 0 0]\n",
      "  Skipping CF preprocessing - EcoliVsKpneumoniae_ramanspy_singular CFs already preprocessed\n",
      "- Evaluating 'Glacier_local_ne'\n",
      "  [Glacier] loaded cf_fold1_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold2_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold3_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold4_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold5_ne.npz: 100 samples\n",
      "  [Glacier] concatenated local/ne: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "  DEBUG: y_pred unique: [0 1]\n",
      "  DEBUG: y_cf unique: [0 1]\n",
      "  DEBUG: y_true unique: [0 1]\n",
      "  DEBUG: First 5 - y_pred: [1 1 0 1 0], y_true: [1 1 0 0 0]\n",
      "  Skipping CF preprocessing - EcoliVsKpneumoniae_ramanspy_singular CFs already preprocessed\n",
      "- Evaluating 'Glacier_global_ne'\n",
      "  [Glacier] loaded cf_fold1_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold2_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold3_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold4_ne.npz: 100 samples\n",
      "  [Glacier] loaded cf_fold5_ne.npz: 100 samples\n",
      "  [Glacier] concatenated global/ne: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "  DEBUG: y_pred unique: [0 1]\n",
      "  DEBUG: y_cf unique: [0 1]\n",
      "  DEBUG: y_true unique: [0 1]\n",
      "  DEBUG: First 5 - y_pred: [1 1 0 1 0], y_true: [1 1 0 0 0]\n",
      "  Skipping CF preprocessing - EcoliVsKpneumoniae_ramanspy_singular CFs already preprocessed\n",
      "- Evaluating 'CELS_local_cels'\n",
      "  [CELS] loaded cf_fold0.npz: 100 samples\n",
      "  [CELS] loaded cf_fold1.npz: 100 samples\n",
      "  [CELS] loaded cf_fold2.npz: 100 samples\n",
      "  [CELS] loaded cf_fold3.npz: 100 samples\n",
      "  [CELS] loaded cf_fold4.npz: 100 samples\n",
      "  [CELS] concatenated local: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "  DEBUG: y_pred unique: [0 1]\n",
      "  DEBUG: y_cf unique: [0 1]\n",
      "  DEBUG: y_true unique: [0 1]\n",
      "  DEBUG: First 5 - y_pred: [1 1 0 0 0], y_true: [1 1 0 0 0]\n",
      "  Skipping CF preprocessing - EcoliVsKpneumoniae_ramanspy_singular CFs already preprocessed\n",
      "- Evaluating 'CELS_global_cels'\n",
      "  [CELS] loaded cf_fold0.npz: 100 samples\n",
      "  [CELS] loaded cf_fold1.npz: 100 samples\n",
      "  [CELS] loaded cf_fold2.npz: 100 samples\n",
      "  [CELS] loaded cf_fold3.npz: 100 samples\n",
      "  [CELS] loaded cf_fold4.npz: 100 samples\n",
      "  [CELS] concatenated global: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "  DEBUG: y_pred unique: [0 1]\n",
      "  DEBUG: y_cf unique: [0 1]\n",
      "  DEBUG: y_true unique: [0 1]\n",
      "  DEBUG: First 5 - y_pred: [1 1 0 0 0], y_true: [1 1 0 0 0]\n",
      "  Skipping CF preprocessing - EcoliVsKpneumoniae_ramanspy_singular CFs already preprocessed\n",
      "- Evaluating 'RSF_local_rsf'\n",
      "  [RSF] loaded cf_fold0.npz: 100 samples\n",
      "  [RSF] loaded cf_fold1.npz: 100 samples\n",
      "  [RSF] loaded cf_fold2.npz: 100 samples\n",
      "  [RSF] loaded cf_fold3.npz: 100 samples\n",
      "  [RSF] loaded cf_fold4.npz: 100 samples\n",
      "  [RSF] concatenated local: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "  DEBUG: y_pred unique: [0 1]\n",
      "  DEBUG: y_cf unique: [0 1]\n",
      "  DEBUG: y_true unique: [0 1]\n",
      "  DEBUG: First 5 - y_pred: [1 1 0 1 1], y_true: [1 1 0 0 0]\n",
      "  Skipping CF preprocessing - EcoliVsKpneumoniae_ramanspy_singular CFs already preprocessed\n",
      "- Evaluating 'RSF_global_rsf'\n",
      "  [RSF] loaded cf_fold0.npz: 100 samples\n",
      "  [RSF] loaded cf_fold1.npz: 100 samples\n",
      "  [RSF] loaded cf_fold2.npz: 100 samples\n",
      "  [RSF] loaded cf_fold3.npz: 100 samples\n",
      "  [RSF] loaded cf_fold4.npz: 100 samples\n",
      "  [RSF] concatenated global: 500 samples total\n",
      "  Loaded 500 samples (after concat)\n",
      "  DEBUG: y_pred unique: [0 1]\n",
      "  DEBUG: y_cf unique: [0 1]\n",
      "  DEBUG: y_true unique: [0 1]\n",
      "  DEBUG: First 5 - y_pred: [1 1 0 1 1], y_true: [1 1 0 0 0]\n",
      "  Skipping CF preprocessing - EcoliVsKpneumoniae_ramanspy_singular CFs already preprocessed\n",
      "\n",
      "================================================================================\n",
      "SVM EVALUATION RESULTS:\n",
      "================================================================================\n",
      "\n",
      "Metric Definitions:\n",
      "  AFR (Any Flip Rate): % of CFs that changed prediction to ANY other class\n",
      "  MSR (Meaningful Success Rate): % of CFs with correct original -> correct target flip\n",
      "  CSR (Conditional Success Rate): Success rate GIVEN ground truth AND SVM agree original was correct\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_48ed0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_48ed0_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_48ed0_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_48ed0_level0_col2\" class=\"col_heading level0 col2\" >AFR</th>\n",
       "      <th id=\"T_48ed0_level0_col3\" class=\"col_heading level0 col3\" >MSR</th>\n",
       "      <th id=\"T_48ed0_level0_col4\" class=\"col_heading level0 col4\" >CSR</th>\n",
       "      <th id=\"T_48ed0_level0_col5\" class=\"col_heading level0 col5\" >Total_Validated_Correct</th>\n",
       "      <th id=\"T_48ed0_level0_col6\" class=\"col_heading level0 col6\" >Avg_Distance</th>\n",
       "      <th id=\"T_48ed0_level0_col7\" class=\"col_heading level0 col7\" >Avg_Rel_Proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_48ed0_row0_col0\" class=\"data row0 col0\" >CELS_global_cels</td>\n",
       "      <td id=\"T_48ed0_row0_col1\" class=\"data row0 col1\" >500</td>\n",
       "      <td id=\"T_48ed0_row0_col2\" class=\"data row0 col2\" >4.2%</td>\n",
       "      <td id=\"T_48ed0_row0_col3\" class=\"data row0 col3\" >2.0%</td>\n",
       "      <td id=\"T_48ed0_row0_col4\" class=\"data row0 col4\" >2.0%</td>\n",
       "      <td id=\"T_48ed0_row0_col5\" class=\"data row0 col5\" >491</td>\n",
       "      <td id=\"T_48ed0_row0_col6\" class=\"data row0 col6\" >1.307000</td>\n",
       "      <td id=\"T_48ed0_row0_col7\" class=\"data row0 col7\" >0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_48ed0_row1_col0\" class=\"data row1 col0\" >CELS_local_cels</td>\n",
       "      <td id=\"T_48ed0_row1_col1\" class=\"data row1 col1\" >500</td>\n",
       "      <td id=\"T_48ed0_row1_col2\" class=\"data row1 col2\" >8.4%</td>\n",
       "      <td id=\"T_48ed0_row1_col3\" class=\"data row1 col3\" >5.2%</td>\n",
       "      <td id=\"T_48ed0_row1_col4\" class=\"data row1 col4\" >5.3%</td>\n",
       "      <td id=\"T_48ed0_row1_col5\" class=\"data row1 col5\" >491</td>\n",
       "      <td id=\"T_48ed0_row1_col6\" class=\"data row1 col6\" >1.911000</td>\n",
       "      <td id=\"T_48ed0_row1_col7\" class=\"data row1 col7\" >0.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_48ed0_row2_col0\" class=\"data row2 col0\" >Glacier_global_cnn</td>\n",
       "      <td id=\"T_48ed0_row2_col1\" class=\"data row2 col1\" >500</td>\n",
       "      <td id=\"T_48ed0_row2_col2\" class=\"data row2 col2\" >44.2%</td>\n",
       "      <td id=\"T_48ed0_row2_col3\" class=\"data row2 col3\" >34.2%</td>\n",
       "      <td id=\"T_48ed0_row2_col4\" class=\"data row2 col4\" >35.8%</td>\n",
       "      <td id=\"T_48ed0_row2_col5\" class=\"data row2 col5\" >477</td>\n",
       "      <td id=\"T_48ed0_row2_col6\" class=\"data row2 col6\" >1.045000</td>\n",
       "      <td id=\"T_48ed0_row2_col7\" class=\"data row2 col7\" >0.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_48ed0_row3_col0\" class=\"data row3 col0\" >Glacier_global_ne</td>\n",
       "      <td id=\"T_48ed0_row3_col1\" class=\"data row3 col1\" >500</td>\n",
       "      <td id=\"T_48ed0_row3_col2\" class=\"data row3 col2\" >24.6%</td>\n",
       "      <td id=\"T_48ed0_row3_col3\" class=\"data row3 col3\" >16.4%</td>\n",
       "      <td id=\"T_48ed0_row3_col4\" class=\"data row3 col4\" >17.2%</td>\n",
       "      <td id=\"T_48ed0_row3_col5\" class=\"data row3 col5\" >477</td>\n",
       "      <td id=\"T_48ed0_row3_col6\" class=\"data row3 col6\" >0.556000</td>\n",
       "      <td id=\"T_48ed0_row3_col7\" class=\"data row3 col7\" >0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_48ed0_row4_col0\" class=\"data row4 col0\" >Glacier_local_cnn</td>\n",
       "      <td id=\"T_48ed0_row4_col1\" class=\"data row4 col1\" >500</td>\n",
       "      <td id=\"T_48ed0_row4_col2\" class=\"data row4 col2\" >24.6%</td>\n",
       "      <td id=\"T_48ed0_row4_col3\" class=\"data row4 col3\" >16.4%</td>\n",
       "      <td id=\"T_48ed0_row4_col4\" class=\"data row4 col4\" >17.2%</td>\n",
       "      <td id=\"T_48ed0_row4_col5\" class=\"data row4 col5\" >477</td>\n",
       "      <td id=\"T_48ed0_row4_col6\" class=\"data row4 col6\" >0.939000</td>\n",
       "      <td id=\"T_48ed0_row4_col7\" class=\"data row4 col7\" >0.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_48ed0_row5_col0\" class=\"data row5 col0\" >Glacier_local_ne</td>\n",
       "      <td id=\"T_48ed0_row5_col1\" class=\"data row5 col1\" >500</td>\n",
       "      <td id=\"T_48ed0_row5_col2\" class=\"data row5 col2\" >9.2%</td>\n",
       "      <td id=\"T_48ed0_row5_col3\" class=\"data row5 col3\" >2.2%</td>\n",
       "      <td id=\"T_48ed0_row5_col4\" class=\"data row5 col4\" >2.3%</td>\n",
       "      <td id=\"T_48ed0_row5_col5\" class=\"data row5 col5\" >477</td>\n",
       "      <td id=\"T_48ed0_row5_col6\" class=\"data row5 col6\" >0.699000</td>\n",
       "      <td id=\"T_48ed0_row5_col7\" class=\"data row5 col7\" >0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_48ed0_row6_col0\" class=\"data row6 col0\" >RSF_global_rsf</td>\n",
       "      <td id=\"T_48ed0_row6_col1\" class=\"data row6 col1\" >500</td>\n",
       "      <td id=\"T_48ed0_row6_col2\" class=\"data row6 col2\" >78.6%</td>\n",
       "      <td id=\"T_48ed0_row6_col3\" class=\"data row6 col3\" >4.4%</td>\n",
       "      <td id=\"T_48ed0_row6_col4\" class=\"data row6 col4\" >5.4%</td>\n",
       "      <td id=\"T_48ed0_row6_col5\" class=\"data row6 col5\" >404</td>\n",
       "      <td id=\"T_48ed0_row6_col6\" class=\"data row6 col6\" >1.380000</td>\n",
       "      <td id=\"T_48ed0_row6_col7\" class=\"data row6 col7\" >0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_48ed0_row7_col0\" class=\"data row7 col0\" >RSF_local_rsf</td>\n",
       "      <td id=\"T_48ed0_row7_col1\" class=\"data row7 col1\" >500</td>\n",
       "      <td id=\"T_48ed0_row7_col2\" class=\"data row7 col2\" >20.6%</td>\n",
       "      <td id=\"T_48ed0_row7_col3\" class=\"data row7 col3\" >1.6%</td>\n",
       "      <td id=\"T_48ed0_row7_col4\" class=\"data row7 col4\" >2.0%</td>\n",
       "      <td id=\"T_48ed0_row7_col5\" class=\"data row7 col5\" >404</td>\n",
       "      <td id=\"T_48ed0_row7_col6\" class=\"data row7 col6\" >0.974000</td>\n",
       "      <td id=\"T_48ed0_row7_col7\" class=\"data row7 col7\" >0.071000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f069e7a9ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BactMetrics = run_comprehensive_evaluation(\n",
    "    \"EcoliVsKpneumoniae_ramanspy_singular\", \n",
    "    use_ramanspy_preprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
